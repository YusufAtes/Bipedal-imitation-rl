
policy_kwargs = dict(net_arch=dict(pi=[128, 64], vf=[128, 64]))
self.update_const = 0.45
self.control_freq = 10
learning_rate=0.0002
ent_coef = 0.01
self.max_torque = 500
    !!!!!!!!!   REF POSITIONS INDEXES ARE WRONG !!!!!!!!!!!!!
     def biped_reward(self,x,torques):

        self.alive_weight = 0.25
        self.forward_weight = 0.25
        self.contact_weight = 0.35
        done = False
        reward = 0
        contact_points = self.p.getContactPoints(self.robot, self.planeId)
        # Conditions for early termination regarding stability

        if not contact_points:
            reward -=1  * self.contact_weight
        elif len(contact_points) > 2:
            reward +=1   * self.contact_weight
        else:
            reward -=1  * self.contact_weight
        
        if x[3] < 0:
            reward -= 1 * self.forward_weight

        if (x[7] > 0.15) and (x[10] > 0.15):
            reward -=1  * self.alive_weight
        elif (x[7] < -0.15) and (x[10] < -0.15):
            reward -=1  * self.alive_weight
        else:
            reward += 1 * self.alive_weight

        if x[4] > 1.5:
            reward -=10
            done = True
        elif x[4] > 1.2:
            reward -= self.alive_weight
        elif x[4] < 0.7:
            reward -=10
            done = True
        elif x[4] < 1.0:
            reward -= 1 * self.alive_weight
        else:
            reward += 1 * self.alive_weight

        hip_joint_pos = x[[7,10]]
        hip_ref_pos = x[[41,44]]
        reward += 0.8*np.exp(-5*np.linalg.norm(hip_joint_pos - hip_ref_pos))

        knee_joint_pos = x[[8,11]]
        knee_ref_pos = x[[42,45]]
        reward += 0.8*np.exp(-5*np.linalg.norm(knee_joint_pos - knee_ref_pos))

        ankle_joint_pos = x[[9,12]]
        ankle_ref_pos = x[[43,46]]
        reward += 0.2*np.exp(-3*np.linalg.norm(ankle_joint_pos - ankle_ref_pos))

        hip_joint_vel = x[[35,38]]
        hip_ref_vel = x[[52,55]]
        reward += 0.8*np.exp(-5*np.linalg.norm(hip_joint_vel - hip_ref_vel))

        knee_joint_vel = x[[36,39]]
        knee_ref_vel = x[[53,56]]
        reward += 0.8*np.exp(-5*np.linalg.norm(knee_joint_vel - knee_ref_vel))

        ankle_joint_vel = x[[37,40]]
        ankle_ref_vel = x[[54,57]]
        reward += 0.2 * np.exp(-3*np.linalg.norm(ankle_joint_vel - ankle_ref_vel))

        reward -= 5e-4 * np.mean(np.abs(torques))
        reward += x[3] * 1e-1

        reward += 0.8*np.exp(-5*np.linalg.norm(x[5] - x[0]))

        return reward, done