{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ezc3d import c3d\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def lowpass_filter_data(data, cutoff=4, fs=100, order=4):\n",
    "    \"\"\"\n",
    "    Apply a Butterworth lowpass filter to the data along each column.\n",
    "\n",
    "    Parameters:\n",
    "      data   : 2D NumPy array of shape (n, 5)\n",
    "      cutoff : Cutoff frequency in Hz (default is 4 Hz)\n",
    "      fs     : Original sampling frequency (default is 100 Hz)\n",
    "      order  : Order of the Butterworth filter (default is 4)\n",
    "    \n",
    "    Returns:\n",
    "      Filtered data as a NumPy array with the same shape as the input.\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs                  # Nyquist Frequency\n",
    "    normal_cutoff = cutoff / nyq    # Normalized cutoff frequency\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    # Use filtfilt to avoid phase shift.\n",
    "    filtered_data = filtfilt(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "def downsample(data, orig_rate=100, new_rate=10):\n",
    "    \"\"\"\n",
    "    Downsample the data from orig_rate to new_rate by taking every (orig_rate/new_rate)-th sample.\n",
    "    \n",
    "    Parameters:\n",
    "      data      : 2D NumPy array of shape (n, 5)\n",
    "      orig_rate : Original sampling frequency (Hz)\n",
    "      new_rate  : Desired sampling frequency (Hz)\n",
    "    \n",
    "    Returns:\n",
    "      Downsampled data.\n",
    "    \"\"\"\n",
    "    factor = orig_rate // new_rate\n",
    "    return data[::factor]\n",
    "\n",
    "def find_near_zero_blocks(data, tol=1e-2, min_gap=30):\n",
    "    \"\"\"\n",
    "    Identify the start indices of contiguous blocks where all 5 columns are near zero.\n",
    "    A new near-zero block is only accepted if it is at least 'min_gap' samples after the previous one.\n",
    "\n",
    "    Parameters:\n",
    "      data    : 2D NumPy array of shape (n, 5)\n",
    "      tol     : Tolerance to consider a value as zero (default is 1e-2)\n",
    "      min_gap : Minimum number of samples between consecutive near-zero blocks (default is 30)\n",
    "    \n",
    "    Returns:\n",
    "      A NumPy array of filtered start indices for near-zero blocks.\n",
    "    \"\"\"\n",
    "    # Create a boolean mask that is True when all 5 columns are nearly zero.\n",
    "    near_zero = np.all(np.abs(data[:,:4]) < tol, axis=0)\n",
    "    \n",
    "    # Compute differences to identify transitions from non-zero to near-zero.\n",
    "    diff = np.diff(near_zero.astype(int))\n",
    "    starts = np.where(near_zero == True)[0]   # +1 to point to the first True value in the block\n",
    "    \n",
    "    # If the very first sample is near zero, include index 0.\n",
    "    if near_zero[0]:\n",
    "        starts = np.insert(starts, 0, 0)\n",
    "    \n",
    "    # Filter out indices that are too close together.\n",
    "    filtered_starts = []\n",
    "    if len(starts) > 0:\n",
    "        filtered_starts.append(starts[0])\n",
    "        for idx in starts[1:]:\n",
    "            if idx - filtered_starts[-1] >= min_gap:\n",
    "                filtered_starts.append(idx)\n",
    "    \n",
    "    return np.array(filtered_starts)\n",
    "\n",
    "def find_cycle_boundaries(data, tol=1e-2, min_gap=30):\n",
    "    \"\"\"\n",
    "    Identify cycle boundaries in the periodic data. Here, a cycle is assumed to start at the first \n",
    "    near-zero block and end at the start of the next near-zero block that is at least 'min_gap' samples later.\n",
    "    \n",
    "    Parameters:\n",
    "      data    : 2D NumPy array (downsampled) of shape (n, 5)\n",
    "      tol     : Tolerance to consider a value as zero (default is 1e-2)\n",
    "      min_gap : Minimum number of samples between consecutive near-zero blocks (default is 30)\n",
    "    \n",
    "    Returns:\n",
    "      A tuple (cycle_start, cycle_stop) indicating the start and stop indices of one cycle.\n",
    "    \"\"\"\n",
    "    near_zero_starts = find_near_zero_blocks(data, tol, min_gap)\n",
    "    \n",
    "    if len(near_zero_starts) < 2:\n",
    "        raise ValueError(\"Not enough near-zero regions found to determine a cycle!\")\n",
    "    \n",
    "    cycle_start = near_zero_starts[0]\n",
    "    cycle_stop = near_zero_starts[1]\n",
    "    return cycle_start, cycle_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lowpass_filter(data, cutoff=5, fs=100, order=4):\n",
    "#     nyquist = 0.5 * fs\n",
    "#     normal_cutoff = cutoff / nyquist\n",
    "#     b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "#     y = filtfilt(b, a, data, axis=0)\n",
    "#     return y\n",
    "\n",
    "def extract_gait_cycle(c, gait_duration=3):\n",
    "\n",
    "    times = c[\"parameters\"][\"EVENT\"][\"TIMES\"]['value']\n",
    "    contexts = c[\"parameters\"][\"EVENT\"][\"CONTEXTS\"]['value']\n",
    "    labels = c[\"parameters\"][\"EVENT\"][\"LABELS\"]['value']\n",
    "    gait_points = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        if (labels[i] == \"Foot Strike1\") and (contexts[i] == \"Right\"):\n",
    "            gait_start = int(times[1,i]*100)\n",
    "        if (labels[i] == \"Foot Strike2\") and (contexts[i] == \"Right\"):\n",
    "            gait_end = int(times[1,i]*100)\n",
    "\n",
    "    trial_data = c['data']['points']\n",
    "    labels = c['parameters']['POINT']['LABELS']['value']\n",
    "\n",
    "    #[15,4,16,5,20,9]\n",
    "    r_ftc = labels.index(\"R_FTC\") if \"R_FTC\" in labels else RuntimeError(\"R_FTC not found\")\n",
    "    l_ftc = labels.index(\"L_FTC\") if \"L_FTC\" in labels else RuntimeError(\"L_FTC not found\")\n",
    "    r_fle = labels.index(\"R_FLE\") if \"R_FLE\" in labels else RuntimeError(\"R_FLE not found\")\n",
    "    l_fle = labels.index(\"L_FLE\") if \"L_FLE\" in labels else RuntimeError(\"L_FLE not found\")\n",
    "    r_fal = labels.index(\"R_FAL\") if \"R_FAL\" in labels else RuntimeError(\"R_FAL not found\")\n",
    "    l_fal = labels.index(\"L_FAL\") if \"L_FAL\" in labels else RuntimeError(\"L_FAL not found\")\n",
    "    r_fcc = labels.index(\"R_FCC\") if \"R_FCC\" in labels else RuntimeError(\"R_FCC not found\")\n",
    "    r_fm1 = labels.index(\"R_FM1\") if \"R_FM1\" in labels else RuntimeError(\"R_FM1 not found\")\n",
    "    l_fcc = labels.index(\"L_FCC\") if \"L_FCC\" in labels else RuntimeError(\"L_FCC not found\")\n",
    "    l_fm1 = labels.index(\"L_FM1\") if \"L_FM1\" in labels else RuntimeError(\"L_FM1 not found\")\n",
    "\n",
    "    sjn = labels.index(\"SJN\") if \"SJN\" in labels else RuntimeError(\"SJN not found\")\n",
    "    sxs = labels.index(\"SXS\") if \"SXS\" in labels else RuntimeError(\"SXS not found\")\n",
    "\n",
    "    r_leglength_ind = c['parameters']['SUBJECT']['LABELS']['value'].index(\"R_legLength\") if \"R_legLength\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"R_LEGLENGTH not found\")\n",
    "    l_leglength_ind = c['parameters']['SUBJECT']['LABELS']['value'].index(\"L_legLength\") if \"L_legLength\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"L_LEGLENGTH not found\")\n",
    "    weight = c['parameters']['SUBJECT']['LABELS']['value'].index(\"weight\") if \"weight\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"Weight not found\")\n",
    "    height = c['parameters']['SUBJECT']['LABELS']['value'].index(\"height\") if \"height\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"Height not found\")\n",
    "    r_leglength = c['parameters']['SUBJECT']['VALUES']['value'][r_leglength_ind]\n",
    "    l_leglength = c['parameters']['SUBJECT']['VALUES']['value'][l_leglength_ind]\n",
    "    weight = c['parameters']['SUBJECT']['VALUES']['value'][weight]\n",
    "    height = c['parameters']['SUBJECT']['VALUES']['value'][height]\n",
    "\n",
    "    muscle_index = [r_ftc,l_ftc,r_fle,l_fle,r_fal,l_fal,sxs,sjn,r_fcc,r_fm1,l_fcc,l_fm1]\n",
    "    joint_data = trial_data[:,muscle_index,:]\n",
    "    joint_states = np.zeros((joint_data.shape[2],4))\n",
    "\n",
    "    data_len = joint_data.shape[2]\n",
    "\n",
    "    first_pos = trial_data[0,sxs,0]\n",
    "    last_pos = trial_data[0,sxs,-1]\n",
    "\n",
    "    if last_pos > first_pos:\n",
    "        forward_walk = True\n",
    "    else:\n",
    "        forward_walk = False\n",
    "\n",
    "    speed_muscle = trial_data[:,sxs,:]\n",
    "    speed = (np.abs(speed_muscle[0,-1]-speed_muscle[0,0])/(len(speed_muscle[0,:])))/10\n",
    "    #data_point[:,-1] = speed\n",
    "\n",
    "    if forward_walk:\n",
    "        for i in range(data_len):\n",
    "            joint_states[i,0] = np.arctan2((joint_data[0,2,i] - joint_data[0,0,i])   , (-joint_data[2,2,i] + joint_data[2,0,i])) \n",
    "            joint_states[i,1] = np.arctan2((joint_data[0,4,i] - joint_data[0,2,i])   , (-joint_data[2,4,i] + joint_data[2,2,i]))  - joint_states[i,0]\n",
    "            joint_states[i,2] = np.arctan2((joint_data[0,3,i] - joint_data[0,1,i])   , (-joint_data[2,3,i] + joint_data[2,1,i]))\n",
    "            joint_states[i,3] = np.arctan2((joint_data[0,5,i] - joint_data[0,3,i])   , (-joint_data[2,5,i] + joint_data[2,3,i]))  - joint_states[i,2]\n",
    "            # joint_states[i,4] = np.arctan2((joint_data[2,9,i] - joint_data[2,8,i])   , (joint_data[0,9,i] - joint_data[0,8,i]))   - joint_states[i,0] - joint_states[i,1]\n",
    "            # joint_states[i,5] = np.arctan2((joint_data[2,11,i] - joint_data[2,10,i]) , (joint_data[0,11,i] - joint_data[0,10,i])) - joint_states[i,2] - joint_states[i,3]\n",
    "            # joint_states[i,4] = speed\n",
    "            # joint_states[i,5] = r_leglength\n",
    "            # joint_states[i,6] = l_leglength\n",
    "    else:\n",
    "        for i in range(data_len):\n",
    "            joint_states[i,0] = np.arctan2((-joint_data[0,2,i] + joint_data[0,0,i]) , (-joint_data[2,2,i] + joint_data[2,0,i])) \n",
    "            joint_states[i,1] = np.arctan2((-joint_data[0,4,i] + joint_data[0,2,i]) , (-joint_data[2,4,i] + joint_data[2,2,i])) - joint_states[i,0]\n",
    "            joint_states[i,2] = np.arctan2((-joint_data[0,3,i] + joint_data[0,1,i]) , (-joint_data[2,3,i] + joint_data[2,1,i]))\n",
    "            joint_states[i,3] = np.arctan2((-joint_data[0,5,i] + joint_data[0,3,i]) , (-joint_data[2,5,i] + joint_data[2,3,i])) - joint_states[i,2]\n",
    "            # joint_states[i,4] = np.arctan2((joint_data[2,9,i] - joint_data[2,8,i])   ,(-joint_data[0,9,i] + joint_data[0,8,i]))   - joint_states[i,0] - joint_states[i,1]\n",
    "            # joint_states[i,5] = np.arctan2((joint_data[2,11,i] - joint_data[2,10,i]) ,(-joint_data[0,11,i] + joint_data[0,10,i])) - joint_states[i,2] - joint_states[i,3]\n",
    "            # joint_states[i,4] = speed\n",
    "            # joint_states[i,5] = r_leglength\n",
    "            # joint_states[i,6] = l_leglength\n",
    "    total_gait_sample = 32\n",
    "    joint_states = lowpass_filter_data(joint_states)\n",
    "    # gait_start, gait_end = find_cycle_boundaries(joint_states, tol=1e-1, min_gap=30)\n",
    "    joint_states = joint_states[gait_start:gait_end,:]\n",
    "    joint_states = downsample(joint_states, orig_rate=100, new_rate=10)\n",
    "    if joint_states.shape[0] > total_gait_sample:\n",
    "        print(f'gait cycle: {joint_states.shape[1]} longer than {gait_duration} seconds')\n",
    "        \n",
    "    while joint_states.shape[0] < total_gait_sample:\n",
    "        joint_states = np.concatenate((joint_states, joint_states),axis=0)  # Stack horizontally\n",
    "\n",
    "    joint_states = joint_states[:total_gait_sample,:]\n",
    "    # padded_joint_states = np.zeros((512, 4))\n",
    "    # padded_joint_states[46:46+joint_states.shape[0],:] = joint_states\n",
    "    \n",
    "    joint_states_rfft = np.fft.rfft(joint_states, n=32,axis=0)\n",
    "    real_fft = np.real(joint_states_rfft)\n",
    "    imag_fft = np.imag(joint_states_rfft)\n",
    "    joint_states_rfft = np.stack((real_fft, imag_fft), axis=2)\n",
    "    freq_values = np.fft.rfftfreq(32, 1/10)\n",
    "    encoder_vec = np.empty((3))   # init_pos + speed + r_leglength + l_leglength + ramp_angle = 0\n",
    "    # encoder_vec[0:4] = joint_states[:,0]\n",
    "    encoder_vec[0] = speed/3\n",
    "    encoder_vec[1] = r_leglength /1.5\n",
    "    encoder_vec[2] = l_leglength /1.5\n",
    "    # encoder_vec[3] = weight / 100  # 100 is the maximum weight in the dataset\n",
    "    # encoder_vec[4] = height / 2    # 1.91 m is the maximum height in the dataset\n",
    "\n",
    "    encoder_vec = encoder_vec[np.newaxis, :]\n",
    "    joint_states_rfft = joint_states_rfft[np.newaxis, :, :] #179 is the maximum value in the dataset\n",
    "    return joint_states_rfft, freq_values, encoder_vec, joint_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/50 is processed current folder is 2014016\n",
      "folder_output_state_shape:  (20, 17, 4, 2)\n",
      "folder input vector shape:  (20, 3)\n",
      "-----------------------------------\n",
      "1/50 is processed current folder is 2014005\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "folder_output_state_shape:  (24, 17, 4, 2)\n",
      "folder input vector shape:  (24, 3)\n",
      "-----------------------------------\n",
      "2/50 is processed current folder is 2014022\n",
      "folder_output_state_shape:  (22, 17, 4, 2)\n",
      "folder input vector shape:  (22, 3)\n",
      "-----------------------------------\n",
      "3/50 is processed current folder is 2014015\n",
      "folder_output_state_shape:  (24, 17, 4, 2)\n",
      "folder input vector shape:  (24, 3)\n",
      "-----------------------------------\n",
      "4/50 is processed current folder is 2014025\n",
      "folder_output_state_shape:  (23, 17, 4, 2)\n",
      "folder input vector shape:  (23, 3)\n",
      "-----------------------------------\n",
      "5/50 is processed current folder is 2015032\n",
      "folder_output_state_shape:  (21, 17, 4, 2)\n",
      "folder input vector shape:  (21, 3)\n",
      "-----------------------------------\n",
      "6/50 is processed current folder is 2015020\n",
      "folder_output_state_shape:  (25, 17, 4, 2)\n",
      "folder input vector shape:  (25, 3)\n",
      "-----------------------------------\n",
      "7/50 is processed current folder is 2015007\n",
      "folder_output_state_shape:  (22, 17, 4, 2)\n",
      "folder input vector shape:  (22, 3)\n",
      "-----------------------------------\n",
      "8/50 is processed current folder is 2014030\n",
      "folder_output_state_shape:  (23, 17, 4, 2)\n",
      "folder input vector shape:  (23, 3)\n",
      "-----------------------------------\n",
      "9/50 is processed current folder is 2014024\n",
      "folder_output_state_shape:  (25, 17, 4, 2)\n",
      "folder input vector shape:  (25, 3)\n",
      "-----------------------------------\n",
      "10/50 is processed current folder is 2014004\n",
      "folder_output_state_shape:  (23, 17, 4, 2)\n",
      "folder input vector shape:  (23, 3)\n",
      "-----------------------------------\n",
      "11/50 is processed current folder is 2014049\n",
      "folder_output_state_shape:  (24, 17, 4, 2)\n",
      "folder input vector shape:  (24, 3)\n",
      "-----------------------------------\n",
      "12/50 is processed current folder is 2014019\n",
      "folder_output_state_shape:  (25, 17, 4, 2)\n",
      "folder input vector shape:  (25, 3)\n",
      "-----------------------------------\n",
      "13/50 is processed current folder is 2015037\n",
      "folder_output_state_shape:  (20, 17, 4, 2)\n",
      "folder input vector shape:  (20, 3)\n",
      "-----------------------------------\n",
      "14/50 is processed current folder is 2014048\n",
      "folder_output_state_shape:  (24, 17, 4, 2)\n",
      "folder input vector shape:  (24, 3)\n",
      "-----------------------------------\n",
      "15/50 is processed current folder is 2014014\n",
      "folder_output_state_shape:  (23, 17, 4, 2)\n",
      "folder input vector shape:  (23, 3)\n",
      "-----------------------------------\n",
      "16/50 is processed current folder is 2014003\n",
      "folder_output_state_shape:  (22, 17, 4, 2)\n",
      "folder input vector shape:  (22, 3)\n",
      "-----------------------------------\n",
      "17/50 is processed current folder is 2015041\n",
      "folder_output_state_shape:  (21, 17, 4, 2)\n",
      "folder input vector shape:  (21, 3)\n",
      "-----------------------------------\n",
      "18/50 is processed current folder is 2015027\n",
      "folder_output_state_shape:  (22, 17, 4, 2)\n",
      "folder input vector shape:  (22, 3)\n",
      "-----------------------------------\n",
      "19/50 is processed current folder is 2015042\n",
      "folder_output_state_shape:  (23, 17, 4, 2)\n",
      "folder input vector shape:  (23, 3)\n",
      "-----------------------------------\n",
      "20/50 is processed current folder is 2015005\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "folder_output_state_shape:  (25, 17, 4, 2)\n",
      "folder input vector shape:  (25, 3)\n",
      "-----------------------------------\n",
      "21/50 is processed current folder is 2015030\n",
      "folder_output_state_shape:  (21, 17, 4, 2)\n",
      "folder input vector shape:  (21, 3)\n",
      "-----------------------------------\n",
      "22/50 is processed current folder is 2015002\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "folder_output_state_shape:  (24, 17, 4, 2)\n",
      "folder input vector shape:  (24, 3)\n",
      "-----------------------------------\n",
      "23/50 is processed current folder is 2014013\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "folder_output_state_shape:  (22, 17, 4, 2)\n",
      "folder input vector shape:  (22, 3)\n",
      "-----------------------------------\n",
      "24/50 is processed current folder is 2015015\n",
      "folder_output_state_shape:  (22, 17, 4, 2)\n",
      "folder input vector shape:  (22, 3)\n",
      "-----------------------------------\n",
      "25/50 is processed current folder is 2014051\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "folder_output_state_shape:  (22, 17, 4, 2)\n",
      "folder input vector shape:  (22, 3)\n",
      "-----------------------------------\n",
      "26/50 is processed current folder is 2014050\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "folder_output_state_shape:  (25, 17, 4, 2)\n",
      "folder input vector shape:  (25, 3)\n",
      "-----------------------------------\n",
      "27/50 is processed current folder is 2014034\n",
      "folder_output_state_shape:  (21, 17, 4, 2)\n",
      "folder input vector shape:  (21, 3)\n",
      "-----------------------------------\n",
      "28/50 is processed current folder is 2015043\n",
      "folder_output_state_shape:  (24, 17, 4, 2)\n",
      "folder input vector shape:  (24, 3)\n",
      "-----------------------------------\n",
      "29/50 is processed current folder is 2014053\n",
      "folder_output_state_shape:  (25, 17, 4, 2)\n",
      "folder input vector shape:  (25, 3)\n",
      "-----------------------------------\n",
      "30/50 is processed current folder is 2015026\n",
      "folder_output_state_shape:  (20, 17, 4, 2)\n",
      "folder input vector shape:  (20, 3)\n",
      "-----------------------------------\n",
      "31/50 is processed current folder is 2014002\n",
      "folder_output_state_shape:  (20, 17, 4, 2)\n",
      "folder input vector shape:  (20, 3)\n",
      "-----------------------------------\n",
      "32/50 is processed current folder is 2015013\n",
      "folder_output_state_shape:  (24, 17, 4, 2)\n",
      "folder input vector shape:  (24, 3)\n",
      "-----------------------------------\n",
      "33/50 is processed current folder is 2015003\n",
      "folder_output_state_shape:  (24, 17, 4, 2)\n",
      "folder input vector shape:  (24, 3)\n",
      "-----------------------------------\n",
      "34/50 is processed current folder is 2015017\n",
      "folder_output_state_shape:  (25, 17, 4, 2)\n",
      "folder input vector shape:  (25, 3)\n",
      "-----------------------------------\n",
      "35/50 is processed current folder is 2014033\n",
      "folder_output_state_shape:  (20, 17, 4, 2)\n",
      "folder input vector shape:  (20, 3)\n",
      "-----------------------------------\n",
      "36/50 is processed current folder is 2014007\n",
      "folder_output_state_shape:  (23, 17, 4, 2)\n",
      "folder input vector shape:  (23, 3)\n",
      "-----------------------------------\n",
      "37/50 is processed current folder is 2014006\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "folder_output_state_shape:  (22, 17, 4, 2)\n",
      "folder input vector shape:  (22, 3)\n",
      "-----------------------------------\n",
      "38/50 is processed current folder is 2015021\n",
      "folder_output_state_shape:  (23, 17, 4, 2)\n",
      "folder input vector shape:  (23, 3)\n",
      "-----------------------------------\n",
      "39/50 is processed current folder is 2014031\n",
      "folder_output_state_shape:  (23, 17, 4, 2)\n",
      "folder input vector shape:  (23, 3)\n",
      "-----------------------------------\n",
      "40/50 is processed current folder is 2015004\n",
      "folder_output_state_shape:  (25, 17, 4, 2)\n",
      "folder input vector shape:  (25, 3)\n",
      "-----------------------------------\n",
      "41/50 is processed current folder is 2014011\n",
      "folder_output_state_shape:  (22, 17, 4, 2)\n",
      "folder input vector shape:  (22, 3)\n",
      "-----------------------------------\n",
      "42/50 is processed current folder is 2014001\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "folder_output_state_shape:  (25, 17, 4, 2)\n",
      "folder input vector shape:  (25, 3)\n",
      "-----------------------------------\n",
      "43/50 is processed current folder is 2014029\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "folder_output_state_shape:  (25, 17, 4, 2)\n",
      "folder input vector shape:  (25, 3)\n",
      "-----------------------------------\n",
      "44/50 is processed current folder is 2014046\n",
      "folder_output_state_shape:  (23, 17, 4, 2)\n",
      "folder input vector shape:  (23, 3)\n",
      "-----------------------------------\n",
      "45/50 is processed current folder is 2014008\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "folder_output_state_shape:  (24, 17, 4, 2)\n",
      "folder input vector shape:  (24, 3)\n",
      "-----------------------------------\n",
      "46/50 is processed current folder is 2014040\n",
      "folder_output_state_shape:  (24, 17, 4, 2)\n",
      "folder input vector shape:  (24, 3)\n",
      "-----------------------------------\n",
      "47/50 is processed current folder is 2014009\n",
      "folder_output_state_shape:  (24, 17, 4, 2)\n",
      "folder input vector shape:  (24, 3)\n",
      "-----------------------------------\n",
      "48/50 is processed current folder is 2014052\n",
      "gait cycle: 4 longer than 2 seconds\n",
      "folder_output_state_shape:  (18, 17, 4, 2)\n",
      "folder input vector shape:  (18, 3)\n",
      "-----------------------------------\n",
      "49/50 is processed current folder is 2015035\n",
      "folder_output_state_shape:  (22, 17, 4, 2)\n",
      "folder input vector shape:  (22, 3)\n",
      "-----------------------------------\n",
      "total output state  (1143, 17, 4, 2)\n",
      "total input vector  (1143, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "gait_duration = 2\n",
    "folders = [d for d in os.listdir(os.path.join(os.getcwd(),'dataset')) if os.path.isdir(os.path.join(os.path.join(os.getcwd(),'dataset'), d))]\n",
    "k=0\n",
    "if os.path.exists(f\"gait reference fft_plots_\") == False:\n",
    "    os.mkdir(f\"gait reference fft_plots_\")\n",
    "\n",
    "for folder in folders:\n",
    "    folder_len = len(folder)\n",
    "    files = [f for f in os.listdir(os.path.join(os.getcwd(),'dataset',folder)) if f.endswith('.c3d')]\n",
    "    \n",
    "    print(f\"{k}/{len(folders)} is processed current folder is {folder}\") \n",
    "    i = 0\n",
    "    for file in files:\n",
    "        if 'ST' not in file:\n",
    "            c = c3d(os.path.join('dataset',folder,file))\n",
    "            joint_states_rfft, freq_values, encoder_vec, joint_states = extract_gait_cycle(c,gait_duration=gait_duration)\n",
    "            # if np.max(np.abs(joint_states)) > 1:\n",
    "            #     print(f'joint_states max value is greater than 1 in {folder}_{file[:-4]}')\n",
    "            #     break\n",
    "            if i == 0:\n",
    "                folder_output_state = joint_states_rfft\n",
    "                folder_input_vector = encoder_vec\n",
    "            else:\n",
    "                folder_output_state = np.vstack((folder_output_state,joint_states_rfft))\n",
    "                folder_input_vector = np.vstack((folder_input_vector,encoder_vec))\n",
    "            i+=1\n",
    "    print('folder_output_state_shape: ',folder_output_state.shape)\n",
    "    print('folder input vector shape: ',folder_input_vector.shape)\n",
    "    print('-----------------------------------')\n",
    "    if k == 0:\n",
    "        total_output_state = folder_output_state\n",
    "        total_input_vector = folder_input_vector\n",
    "    else:\n",
    "        total_output_state = np.vstack((total_output_state,folder_output_state))\n",
    "        total_input_vector = np.vstack((total_input_vector,folder_input_vector))\n",
    "    k+=1\n",
    "#     np.save(f\"ref_gait_library_duration{gait_duration}/{folder}_output_state.npy\",folder_output_state)\n",
    "#     np.save(f\"ref_gait_library_duration{gait_duration}/{folder}_input_vector.npy\",folder_input_vector)\n",
    "\n",
    "if os.path.exists(f\"gait reference fft{freq_values[-1]:.2f}\") == False:\n",
    "    os.mkdir(f\"gait reference fft{freq_values[-1]:.2f}\")\n",
    "\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/output_fft_constants.npy\",total_output_state)\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/input_vector.npy\",total_input_vector)\n",
    "\n",
    "print('total output state ',total_output_state.shape)\n",
    "print('total input vector ',total_input_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7792810314909367\n",
      "0.6131200393040975\n",
      "0.610983689626058\n",
      "(1143, 17, 4, 2)\n",
      "r1_coeff: 18.640146475485608 i1_coeff: 0.0\n",
      "r2_coeff: 4.647393410432269 i2_coeff: 7.339284362006474\n",
      "r3_coeff: 5.650498095270567 i3_coeff: 7.42038311036306\n",
      "r4_coeff: 7.691350763941512 i4_coeff: 8.400825516755768\n",
      "r5_coeff: 7.9291576998954385 i5_coeff: 5.750448885972114\n",
      "r6_coeff: 5.147585541309002 i6_coeff: 4.927635942191211\n",
      "r7_coeff: 5.537468776260772 i7_coeff: 4.350563119374307\n",
      "r8_coeff: 4.673475883443481 i8_coeff: 5.455495743322678\n",
      "r9_coeff: 4.208688019569827 i9_coeff: 5.481883956717162\n",
      "r10_coeff: 1.7809764927468497 i10_coeff: 1.8288584139096575\n",
      "r11_coeff: 1.3685216315022963 i11_coeff: 1.6905349591461332\n",
      "r12_coeff: 1.5025137863566582 i12_coeff: 1.366551160973413\n",
      "r13_coeff: 0.7816124090047333 i13_coeff: 1.2790148780907262\n",
      "r14_coeff: 0.832538895034308 i14_coeff: 0.7966805331779563\n",
      "r15_coeff: 0.5969407968659162 i15_coeff: 0.3399243784148428\n",
      "r16_coeff: 0.5659848552269097 i16_coeff: 0.35234033954450983\n",
      "r17_coeff: 1.3641296362349822 i17_coeff: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(np.abs(total_input_vector[:,0])))  # speed\n",
    "print(np.max(np.abs(total_input_vector[:,1])))  # r_leglength\n",
    "print(np.max(np.abs(total_input_vector[:,2])))  # l_leglength\n",
    "\n",
    "print(total_output_state.shape)                 #shape of the vector\n",
    "\n",
    "r1_coeff = np.max(np.abs(total_output_state[:,0,:,0]))\n",
    "i1_coeff = np.max(np.abs(total_output_state[:,0,:,1]))\n",
    "r2_coeff = np.max(np.abs(total_output_state[:,1,:,0]))\n",
    "i2_coeff = np.max(np.abs(total_output_state[:,1,:,1]))\n",
    "r3_coeff = np.max(np.abs(total_output_state[:,2,:,0]))\n",
    "i3_coeff = np.max(np.abs(total_output_state[:,2,:,1]))\n",
    "r4_coeff = np.max(np.abs(total_output_state[:,3,:,0]))\n",
    "i4_coeff = np.max(np.abs(total_output_state[:,3,:,1]))\n",
    "r5_coeff = np.max(np.abs(total_output_state[:,4,:,0]))\n",
    "i5_coeff = np.max(np.abs(total_output_state[:,4,:,1]))\n",
    "r6_coeff = np.max(np.abs(total_output_state[:,5,:,0]))\n",
    "i6_coeff = np.max(np.abs(total_output_state[:,5,:,1]))\n",
    "r7_coeff = np.max(np.abs(total_output_state[:,6,:,0]))\n",
    "i7_coeff = np.max(np.abs(total_output_state[:,6,:,1]))\n",
    "r8_coeff = np.max(np.abs(total_output_state[:,7,:,0]))\n",
    "i8_coeff = np.max(np.abs(total_output_state[:,7,:,1]))\n",
    "r9_coeff = np.max(np.abs(total_output_state[:,8,:,0]))\n",
    "i9_coeff = np.max(np.abs(total_output_state[:,8,:,1]))\n",
    "r10_coeff = np.max(np.abs(total_output_state[:,9,:,0]))\n",
    "i10_coeff = np.max(np.abs(total_output_state[:,9,:,1]))\n",
    "r11_coeff = np.max(np.abs(total_output_state[:,10,:,0]))\n",
    "i11_coeff = np.max(np.abs(total_output_state[:,10,:,1]))\n",
    "r12_coeff = np.max(np.abs(total_output_state[:,11,:,0]))\n",
    "i12_coeff = np.max(np.abs(total_output_state[:,11,:,1]))\n",
    "r13_coeff = np.max(np.abs(total_output_state[:,12,:,0]))\n",
    "i13_coeff = np.max(np.abs(total_output_state[:,12,:,1]))\n",
    "r14_coeff = np.max(np.abs(total_output_state[:,13,:,0]))\n",
    "i14_coeff = np.max(np.abs(total_output_state[:,13,:,1]))\n",
    "r15_coeff = np.max(np.abs(total_output_state[:,14,:,0]))\n",
    "i15_coeff = np.max(np.abs(total_output_state[:,14,:,1]))\n",
    "r16_coeff = np.max(np.abs(total_output_state[:,15,:,0]))\n",
    "i16_coeff = np.max(np.abs(total_output_state[:,15,:,1]))\n",
    "r17_coeff = np.max(np.abs(total_output_state[:,16,:,0]))\n",
    "i17_coeff = np.max(np.abs(total_output_state[:,16,:,1]))\n",
    "\n",
    "print(f'r1_coeff: {r1_coeff} i1_coeff: {i1_coeff}')\n",
    "print(f'r2_coeff: {r2_coeff} i2_coeff: {i2_coeff}')\n",
    "print(f'r3_coeff: {r3_coeff} i3_coeff: {i3_coeff}')\n",
    "print(f'r4_coeff: {r4_coeff} i4_coeff: {i4_coeff}')\n",
    "print(f'r5_coeff: {r5_coeff} i5_coeff: {i5_coeff}')\n",
    "print(f'r6_coeff: {r6_coeff} i6_coeff: {i6_coeff}')\n",
    "print(f'r7_coeff: {r7_coeff} i7_coeff: {i7_coeff}')\n",
    "print(f'r8_coeff: {r8_coeff} i8_coeff: {i8_coeff}')\n",
    "print(f'r9_coeff: {r9_coeff} i9_coeff: {i9_coeff}')\n",
    "print(f'r10_coeff: {r10_coeff} i10_coeff: {i10_coeff}')\n",
    "print(f'r11_coeff: {r11_coeff} i11_coeff: {i11_coeff}')\n",
    "print(f'r12_coeff: {r12_coeff} i12_coeff: {i12_coeff}')\n",
    "print(f'r13_coeff: {r13_coeff} i13_coeff: {i13_coeff}')\n",
    "print(f'r14_coeff: {r14_coeff} i14_coeff: {i14_coeff}')\n",
    "print(f'r15_coeff: {r15_coeff} i15_coeff: {i15_coeff}')\n",
    "print(f'r16_coeff: {r16_coeff} i16_coeff: {i16_coeff}')\n",
    "print(f'r17_coeff: {r17_coeff} i17_coeff: {i17_coeff}')\n",
    "\n",
    "total_output_state[:,0,:,0] = total_output_state[:,0,:,0]/r1_coeff\n",
    "total_output_state[:,0,:,1] = total_output_state[:,0,:,1]\n",
    "total_output_state[:,1,:,0] = total_output_state[:,1,:,0]/r2_coeff\n",
    "total_output_state[:,1,:,1] = total_output_state[:,1,:,1]/i2_coeff\n",
    "total_output_state[:,2,:,0] = total_output_state[:,2,:,0]/r3_coeff\n",
    "total_output_state[:,2,:,1] = total_output_state[:,2,:,1]/i3_coeff\n",
    "total_output_state[:,3,:,0] = total_output_state[:,3,:,0]/r4_coeff\n",
    "total_output_state[:,3,:,1] = total_output_state[:,3,:,1]/i4_coeff\n",
    "total_output_state[:,4,:,0] = total_output_state[:,4,:,0]/r5_coeff\n",
    "total_output_state[:,4,:,1] = total_output_state[:,4,:,1]/i5_coeff\n",
    "total_output_state[:,5,:,0] = total_output_state[:,5,:,0]/r6_coeff\n",
    "total_output_state[:,5,:,1] = total_output_state[:,5,:,1]/i6_coeff\n",
    "total_output_state[:,6,:,0] = total_output_state[:,6,:,0]/r7_coeff\n",
    "total_output_state[:,6,:,1] = total_output_state[:,6,:,1]/i7_coeff\n",
    "total_output_state[:,7,:,0] = total_output_state[:,7,:,0]/r8_coeff\n",
    "total_output_state[:,7,:,1] = total_output_state[:,7,:,1]/i8_coeff\n",
    "total_output_state[:,8,:,0] = total_output_state[:,8,:,0]/r9_coeff\n",
    "total_output_state[:,8,:,1] = total_output_state[:,8,:,1]/i9_coeff\n",
    "total_output_state[:,9,:,0] = total_output_state[:,9,:,0]/r10_coeff\n",
    "total_output_state[:,9,:,1] = total_output_state[:,9,:,1]/i10_coeff\n",
    "total_output_state[:,10,:,0] = total_output_state[:,10,:,0]/r11_coeff\n",
    "total_output_state[:,10,:,1] = total_output_state[:,10,:,1]/i11_coeff\n",
    "total_output_state[:,11,:,0] = total_output_state[:,11,:,0]/r12_coeff\n",
    "total_output_state[:,11,:,1] = total_output_state[:,11,:,1]/i12_coeff\n",
    "total_output_state[:,12,:,0] = total_output_state[:,12,:,0]/r13_coeff\n",
    "total_output_state[:,12,:,1] = total_output_state[:,12,:,1]/i13_coeff\n",
    "total_output_state[:,13,:,0] = total_output_state[:,13,:,0]/r14_coeff\n",
    "total_output_state[:,13,:,1] = total_output_state[:,13,:,1]/i14_coeff\n",
    "total_output_state[:,14,:,0] = total_output_state[:,14,:,0]/r15_coeff\n",
    "total_output_state[:,14,:,1] = total_output_state[:,14,:,1]/i15_coeff\n",
    "total_output_state[:,15,:,0] = total_output_state[:,15,:,0]/r16_coeff\n",
    "total_output_state[:,15,:,1] = total_output_state[:,15,:,1]/i16_coeff\n",
    "total_output_state[:,16,:,0] = total_output_state[:,16,:,0]/r17_coeff\n",
    "total_output_state[:,16,:,1] = total_output_state[:,16,:,1]\n",
    "\n",
    "\n",
    "#i1 and i17 is zero for all the data points\n",
    "normalizationconst = [r1_coeff,i1_coeff,r2_coeff,i2_coeff,r3_coeff,i3_coeff,r4_coeff,i4_coeff,r5_coeff,i5_coeff,r6_coeff,i6_coeff,r7_coeff,i7_coeff,r8_coeff,i8_coeff,r9_coeff,i9_coeff,r10_coeff,i10_coeff,r11_coeff,i11_coeff,r12_coeff,i12_coeff,r13_coeff,i13_coeff,r14_coeff,i14_coeff,r15_coeff,i15_coeff,r16_coeff,i16_coeff,r17_coeff,i17_coeff]\n",
    "\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/newnormalized_output_fft_constants.npy\",total_output_state)\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/newnormalized_input_vector.npy\",total_input_vector)\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/newnormalization_constants.npy\",normalizationconst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Old Way of Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.901030205290768 5.521259817435723 18.456033746012857 8.203208839185772 7.9291576998954385 6.00687035498604 18.640146475485608 8.400825516755768\n"
     ]
    }
   ],
   "source": [
    "# NORMALIZATION OF THE DATA IS IMPLEMENTED\n",
    "import numpy as np\n",
    "real_rthigh = np.max(np.abs(total_output_state[:,:,0,0]))\n",
    "imag_rthigh = np.max(np.abs(total_output_state[:,:,0,1]))\n",
    "\n",
    "real_rshank = np.max(np.abs(total_output_state[:,:,1,0]))\n",
    "imag_rshank = np.max(np.abs(total_output_state[:,:,1,1]))\n",
    "\n",
    "real_lthigh = np.max(np.abs(total_output_state[:,:,2,0]))\n",
    "imag_lthigh = np.max(np.abs(total_output_state[:,:,2,1]))\n",
    "\n",
    "real_lshank = np.max(np.abs(total_output_state[:,:,3,0]))\n",
    "imag_lshank = np.max(np.abs(total_output_state[:,:,3,1]))\n",
    "\n",
    "print(real_rthigh,imag_rthigh,real_rshank,imag_rshank,real_lthigh,imag_lthigh,real_lshank,imag_lshank)\n",
    "\n",
    "normalizationconst = np.array([real_rthigh,imag_rthigh,real_rshank,imag_rshank,real_lthigh,imag_lthigh,real_lshank,imag_lshank])\n",
    "\n",
    "total_output_state[:,:,0,0] = total_output_state[:,:,0,0] / real_rthigh\n",
    "total_output_state[:,:,1,0] = total_output_state[:,:,1,0] / real_rshank\n",
    "total_output_state[:,:,2,0] = total_output_state[:,:,2,0] / real_lthigh\n",
    "total_output_state[:,:,3,0] = total_output_state[:,:,3,0] / real_lshank\n",
    "\n",
    "total_output_state[:,:,0,1] = total_output_state[:,:,0,1] / imag_rthigh\n",
    "total_output_state[:,:,1,1] = total_output_state[:,:,1,1] / imag_rshank\n",
    "total_output_state[:,:,2,1] = total_output_state[:,:,2,1] / imag_lthigh\n",
    "total_output_state[:,:,3,1] = total_output_state[:,:,3,1] / imag_lshank\n",
    "\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/oldnormalized_output_fft_constants.npy\",total_output_state)\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/oldnormalized_input_vector.npy\",total_input_vector)\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/oldnormalization_constants.npy\",normalizationconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_ifft_plots(joint_states_rfft,joint_states,frequencies,path,crop_ind=30):\n",
    "#     frequency = frequencies[crop_ind]\n",
    "#     joint_states_rfft = 180*np.squeeze(joint_states_rfft)\n",
    "#     cropped = joint_states_rfft.copy()\n",
    "#     cropped[crop_ind:,:] = 0\n",
    "#     ifft = np.fft.irfft(cropped, axis=0)\n",
    "#     cropped_ifft = ifft[56:-56,:]\n",
    "#     fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "#     axs[0, 0].plot(joint_states[:,0])\n",
    "#     axs[0, 0].plot(cropped_ifft[:,0])\n",
    "#     axs[0, 0].legend(['Original', 'Reconstructed'])\n",
    "#     axs[0, 0].set_title('Right Shank')\n",
    "#     axs[0, 1].plot(joint_states[:,1])\n",
    "#     axs[0, 1].plot(cropped_ifft[:,1])\n",
    "#     axs[0, 1].set_title('Right Thigh')\n",
    "#     axs[0, 1].legend(['Original', 'Reconstructed'])\n",
    "#     axs[1, 0].plot(joint_states[:,2])\n",
    "#     axs[1, 0].plot(cropped_ifft[:,2])\n",
    "#     axs[1, 0].set_title('Left Shank')\n",
    "#     axs[1, 0].legend(['Original', 'Reconstructed'])\n",
    "#     axs[1, 1].plot(joint_states[:,3])\n",
    "#     axs[1, 1].plot(cropped_ifft[:,3])\n",
    "#     axs[1, 1].set_title('Left Thigh')\n",
    "#     axs[1, 1].legend(['Original', 'Reconstructed'])\n",
    "#     plt.savefig(path+'.png')\n",
    "#     plt.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(914, 4, 2, 17)\n",
      "(229, 4, 2, 17)\n",
      "train data shape:  torch.Size([914, 3])\n",
      "test data shape:  torch.Size([229, 3])\n",
      "train output shape:  torch.Size([914, 136])\n",
      "test output shape:  torch.Size([229, 136])\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "train_for = \"normal\"\n",
    "\n",
    "inputs = np.load(rf\"gait reference fft5.00/newnormalized_input_vector.npy\")\n",
    "outputs = np.load(rf\"gait reference fft5.00/newnormalized_output_fft_constants.npy\")\n",
    "\n",
    "#train test split using sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.2, random_state=23)\n",
    "\n",
    "y_train = y_train\n",
    "y_train  = y_train.transpose(0,2,3,1)\n",
    "if train_for == \"taga\":\n",
    "    y_train = y_train[:,:4,:,:]\n",
    "print(y_train.shape)\n",
    "y_train = y_train.reshape(y_train.shape[0],-1)\n",
    "y_test = y_test\n",
    "y_test = y_test.transpose(0,2,3,1)\n",
    "if train_for == \"taga\":\n",
    "    y_test = y_test[:,:4,:,:]\n",
    "print(y_test.shape)\n",
    "y_test = y_test.reshape(y_test.shape[0],-1)\n",
    "#convert to tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# create dataloader\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "val_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "print('train data shape: ',X_train.shape)\n",
    "print('test data shape: ',X_test.shape)\n",
    "print('train output shape: ',y_train.shape)\n",
    "print('test output shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New Normalize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(pred,gt,normalizationconst):\n",
    "    #form is [5,2,17]\n",
    "    for i in range(17):\n",
    "        for k in range(2):\n",
    "            pred[:,k,i] = pred[:,k,i] * normalizationconst[i*2+k]\n",
    "            gt[:,k,i] = gt[:,k,i] * normalizationconst[i*2+k]\n",
    "    \n",
    "    return pred,gt\n",
    "\n",
    "def pred_ifft(predictions,ground_truth,speed,normalizationconst):\n",
    "    #form is [5,2,17]\n",
    "    real_pred = predictions[:,0,:]\n",
    "    imag_pred = predictions[:,1,:]\n",
    "    predictions = real_pred + 1j*imag_pred\n",
    "    real_gt = ground_truth[:,0,:]\n",
    "    imag_gt = ground_truth[:,1,:]\n",
    "    ground_truth = real_gt + 1j*imag_gt\n",
    "    \n",
    "\n",
    "    pred_time = np.fft.irfft(predictions, axis=1)\n",
    "    gt_time = np.fft.irfft(ground_truth, axis=1)\n",
    "    pred_time = pred_time.transpose(1,0)\n",
    "    gt_time = gt_time.transpose(1,0)\n",
    "    #plot 2*2 subplots\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(pred_time[:,0])\n",
    "    plt.plot(gt_time[:,0])\n",
    "    plt.title('Right Hip')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(pred_time[:,1])\n",
    "    plt.plot(gt_time[:,1])\n",
    "    plt.title('Right Knee')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(pred_time[:,2])\n",
    "    plt.plot(gt_time[:,2])\n",
    "    plt.title('Left Hip')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(pred_time[:,3])\n",
    "    plt.plot(gt_time[:,3])\n",
    "    plt.title('Left Knee')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "\n",
    "\n",
    "    plt.savefig(f\"compare/new{speed:.2f}ms.png\")\n",
    "    plt.close()\n",
    "    print('plots saved')\n",
    "    return pred_time,gt_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Old Denormalize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(pred,gt,normalizationconst):\n",
    "    #form is [5,2,17]\n",
    "    pred[0,0,:] = pred[0,0,:] * normalizationconst[0]\n",
    "    pred[0,1,:] = pred[0,1,:] * normalizationconst[1]\n",
    "    pred[1,0,:] = pred[1,0,:] * normalizationconst[2]\n",
    "    pred[1,1,:] = pred[1,1,:] * normalizationconst[3]\n",
    "    pred[2,0,:] = pred[2,0,:] * normalizationconst[4]\n",
    "    pred[2,1,:] = pred[2,1,:] * normalizationconst[5]\n",
    "    pred[3,0,:] = pred[3,0,:] * normalizationconst[6]\n",
    "    pred[3,1,:] = pred[3,1,:] * normalizationconst[7]\n",
    "\n",
    "    \n",
    "\n",
    "    gt[0,0,:] = gt[0,0,:] * normalizationconst[0]\n",
    "    gt[0,1,:] = gt[0,1,:] * normalizationconst[1]\n",
    "    gt[1,0,:] = gt[1,0,:] * normalizationconst[2]\n",
    "    gt[1,1,:] = gt[1,1,:] * normalizationconst[3]\n",
    "    gt[2,0,:] = gt[2,0,:] * normalizationconst[4]\n",
    "    gt[2,1,:] = gt[2,1,:] * normalizationconst[5]\n",
    "    gt[3,0,:] = gt[3,0,:] * normalizationconst[6]\n",
    "    gt[3,1,:] = gt[3,1,:] * normalizationconst[7]\n",
    "\n",
    "    \n",
    "    return pred,gt\n",
    "    \n",
    "\n",
    "def pred_ifft(predictions,ground_truth,speed,normalizationconst):\n",
    "    #form is [5,2,17]\n",
    "    real_pred = predictions[:,0,:]\n",
    "    imag_pred = predictions[:,1,:]\n",
    "    predictions = real_pred + 1j*imag_pred\n",
    "    real_gt = ground_truth[:,0,:]\n",
    "    imag_gt = ground_truth[:,1,:]\n",
    "    ground_truth = real_gt + 1j*imag_gt\n",
    "    \n",
    "\n",
    "    pred_time = np.fft.irfft(predictions, axis=1)\n",
    "    gt_time = np.fft.irfft(ground_truth, axis=1)\n",
    "    pred_time = pred_time.transpose(1,0)\n",
    "    gt_time = gt_time.transpose(1,0)\n",
    "    #plot 2*2 subplots\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(pred_time[:,0])\n",
    "    plt.plot(gt_time[:,0])\n",
    "    plt.title('Right Hip')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(pred_time[:,1])\n",
    "    plt.plot(gt_time[:,1])\n",
    "    plt.title('Right Knee')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(pred_time[:,2])\n",
    "    plt.plot(gt_time[:,2])\n",
    "    plt.title('Left Hip')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(pred_time[:,3])\n",
    "    plt.plot(gt_time[:,3])\n",
    "    plt.title('Left Knee')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "\n",
    "    plt.savefig(f\"compare/old_{speed:.2f}ms.png\")\n",
    "    plt.close()\n",
    "    print('plots saved')\n",
    "    return pred_time,gt_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Create the results folder if it does not exist.\n",
    "# -----------------------------\n",
    "if train_for == \"taga\":\n",
    "    results_dir = \"taga_gait_results\"\n",
    "results_dir = \"ref_gait_results_6d_oldnormalize\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Define Custom Loss Function\n",
    "# -----------------------------\n",
    "class CustomWeightedMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomWeightedMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Compute element-wise squared error\n",
    "        squared_error = (predictions - targets) ** 2\n",
    "        # If the absolute prediction is larger than the absolute target, weight = 1.5; otherwise weight = 1.0.\n",
    "        weights = torch.where(torch.abs(predictions) > torch.abs(targets),\n",
    "                              torch.tensor(1.2, device=predictions.device),\n",
    "                              torch.tensor(1.0, device=predictions.device))\n",
    "        weighted_squared_error = weights * squared_error\n",
    "        return torch.mean(weighted_squared_error)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Define Model Architecture\n",
    "# -----------------------------\n",
    "class SimpleFCNN(nn.Module):\n",
    "    def __init__(self, input_size=3, output_size=170, hidden_size=128):\n",
    "        super(SimpleFCNN, self).__init__()\n",
    "        # Layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=32, hidden_size=512, epochs=10000, lr=0.0001\n",
      "  Epoch 200/10000 | Train Loss: 0.023161 | Val Loss: 0.020978\n",
      "  Epoch 400/10000 | Train Loss: 0.020521 | Val Loss: 0.019113\n",
      "  Epoch 600/10000 | Train Loss: 0.019588 | Val Loss: 0.018453\n",
      "  Epoch 800/10000 | Train Loss: 0.018821 | Val Loss: 0.018106\n",
      "  Epoch 1000/10000 | Train Loss: 0.018090 | Val Loss: 0.017736\n",
      "  Epoch 1200/10000 | Train Loss: 0.017763 | Val Loss: 0.017552\n",
      "  Epoch 1400/10000 | Train Loss: 0.017227 | Val Loss: 0.017302\n",
      "  Epoch 1600/10000 | Train Loss: 0.016943 | Val Loss: 0.017169\n",
      "  Epoch 1800/10000 | Train Loss: 0.016992 | Val Loss: 0.016980\n",
      "  Epoch 2000/10000 | Train Loss: 0.016746 | Val Loss: 0.016881\n",
      "  Epoch 2200/10000 | Train Loss: 0.016741 | Val Loss: 0.016706\n",
      "  Epoch 2400/10000 | Train Loss: 0.016564 | Val Loss: 0.016679\n",
      "  Epoch 2600/10000 | Train Loss: 0.016452 | Val Loss: 0.016445\n",
      "  Epoch 2800/10000 | Train Loss: 0.016449 | Val Loss: 0.016514\n",
      "  Epoch 3000/10000 | Train Loss: 0.016062 | Val Loss: 0.016376\n",
      "  Epoch 3200/10000 | Train Loss: 0.015854 | Val Loss: 0.016399\n",
      "  Epoch 3400/10000 | Train Loss: 0.015969 | Val Loss: 0.016304\n",
      "  Epoch 3600/10000 | Train Loss: 0.015478 | Val Loss: 0.016250\n",
      "  Epoch 3800/10000 | Train Loss: 0.015692 | Val Loss: 0.016167\n",
      "  Epoch 4000/10000 | Train Loss: 0.015517 | Val Loss: 0.016094\n",
      "  Epoch 4200/10000 | Train Loss: 0.015603 | Val Loss: 0.016169\n",
      "  Epoch 4400/10000 | Train Loss: 0.015406 | Val Loss: 0.016044\n",
      "  Epoch 4600/10000 | Train Loss: 0.015602 | Val Loss: 0.016042\n",
      "  Epoch 4800/10000 | Train Loss: 0.015358 | Val Loss: 0.016020\n",
      "  Epoch 5000/10000 | Train Loss: 0.015111 | Val Loss: 0.015945\n",
      "  Epoch 5200/10000 | Train Loss: 0.014972 | Val Loss: 0.016002\n",
      "  Epoch 5400/10000 | Train Loss: 0.015157 | Val Loss: 0.016113\n",
      "  Epoch 5600/10000 | Train Loss: 0.014841 | Val Loss: 0.016027\n",
      "  Epoch 5800/10000 | Train Loss: 0.015017 | Val Loss: 0.015904\n",
      "  Epoch 6000/10000 | Train Loss: 0.015028 | Val Loss: 0.015939\n",
      "  Epoch 6200/10000 | Train Loss: 0.015185 | Val Loss: 0.015907\n",
      "  Epoch 6400/10000 | Train Loss: 0.014746 | Val Loss: 0.015845\n",
      "  Epoch 6600/10000 | Train Loss: 0.014517 | Val Loss: 0.015907\n",
      "  Epoch 6800/10000 | Train Loss: 0.014709 | Val Loss: 0.015765\n",
      "  Epoch 7000/10000 | Train Loss: 0.014979 | Val Loss: 0.015776\n",
      "  Epoch 7200/10000 | Train Loss: 0.014763 | Val Loss: 0.015908\n",
      "  Epoch 7400/10000 | Train Loss: 0.014528 | Val Loss: 0.015693\n",
      "  Epoch 7600/10000 | Train Loss: 0.014793 | Val Loss: 0.015726\n",
      "  Epoch 7800/10000 | Train Loss: 0.014777 | Val Loss: 0.015860\n",
      "  Epoch 8000/10000 | Train Loss: 0.014717 | Val Loss: 0.015693\n",
      "  Epoch 8200/10000 | Train Loss: 0.014857 | Val Loss: 0.015768\n",
      "  Epoch 8400/10000 | Train Loss: 0.014480 | Val Loss: 0.015850\n",
      "  Epoch 8600/10000 | Train Loss: 0.014409 | Val Loss: 0.015666\n",
      "  Epoch 8800/10000 | Train Loss: 0.014717 | Val Loss: 0.015619\n",
      "  Epoch 9000/10000 | Train Loss: 0.014514 | Val Loss: 0.015837\n",
      "  Epoch 9200/10000 | Train Loss: 0.014430 | Val Loss: 0.015703\n",
      "  Epoch 9400/10000 | Train Loss: 0.014152 | Val Loss: 0.015604\n",
      "  Epoch 9600/10000 | Train Loss: 0.014624 | Val Loss: 0.015694\n",
      "  Epoch 9800/10000 | Train Loss: 0.014011 | Val Loss: 0.015638\n",
      "  Epoch 10000/10000 | Train Loss: 0.014443 | Val Loss: 0.015696\n",
      " Loss plot saved as ref_gait_results_6d_oldnormalize/loss_plot_bs32_hs512_epochs10000_lr0.0001.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [32]\n",
    "hidden_sizes = [512]\n",
    "num_epochs_list = [10000]  # Number of epochs for training\n",
    "learning_rates = [0.0001]\n",
    "input_size = 3\n",
    "output_size = 136\n",
    "if train_for == \"taga\":\n",
    "    output_size = 136\n",
    "\n",
    "# This list will collect the results from each hyperparameter combination.\n",
    "tuning_results = []\n",
    "\n",
    "# Variables to store the best model and best validation loss\n",
    "best_val_loss = float('inf')\n",
    "best_params = None\n",
    "best_model_state = None\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Hyperparameter Tuning Loop\n",
    "# -----------------------------\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    # Create DataLoader for training and validation using the current batch size.\n",
    "    train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=bs, shuffle=False)\n",
    "    \n",
    "    for hs in hidden_sizes:\n",
    "        for num_epochs in num_epochs_list:\n",
    "            for lr in learning_rates:\n",
    "                print(f\"Training with batch_size={bs}, hidden_size={hs}, epochs={num_epochs}, lr={lr}\")\n",
    "                \n",
    "                # Initialize the model and optimizer for the current hyperparameters.\n",
    "                torch.manual_seed(23)  # Ensure reproducibility per run.\n",
    "                model = SimpleFCNN(input_size=input_size, output_size=output_size, hidden_size=hs)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "                loss_fn = CustomWeightedMSELoss()\n",
    "                \n",
    "                train_losses = []\n",
    "                val_losses = []\n",
    "                \n",
    "                # Training loop for the current hyperparameter combination.\n",
    "                for epoch in range(num_epochs):\n",
    "                    model.train()\n",
    "                    running_train_loss = 0.0\n",
    "                    for inputs, targets in train_loader:\n",
    "                        # Ensure targets are the right shape.\n",
    "                        targets = targets.view(-1, output_size)\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(inputs)\n",
    "                        loss = loss_fn(outputs, targets)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        running_train_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "                    train_losses.append(epoch_train_loss)\n",
    "\n",
    "                    # Optionally print progress every 10 epochs (or at the last epoch)\n",
    "                    if (epoch+1) % 200 == 0 or epoch == num_epochs - 1:\n",
    "                        # Validation loop\n",
    "                        model.eval()\n",
    "                        running_val_loss = 0.0\n",
    "                        with torch.no_grad():\n",
    "                            for inputs, targets in val_loader:\n",
    "                                targets = targets.view(-1, output_size)\n",
    "                                outputs = model(inputs)\n",
    "                                loss = loss_fn(outputs, targets)\n",
    "                                running_val_loss += loss.item() * inputs.size(0)\n",
    "                        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "                        val_losses.append(epoch_val_loss)\n",
    "                        print(f\"  Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_train_loss:.6f} | Val Loss: {epoch_val_loss:.6f}\")\n",
    "                        # Record final losses from this run.\n",
    "                        final_train_loss = train_losses[-1]\n",
    "                        final_val_loss = val_losses[-1]\n",
    "                        result = {\n",
    "                            'batch_size': bs,\n",
    "                            'hidden_size': hs,\n",
    "                            'num_epochs': epoch+1,\n",
    "                            'learning_rate': lr,\n",
    "                            'final_train_loss': final_train_loss,\n",
    "                            'final_val_loss': final_val_loss\n",
    "                        }\n",
    "                        tuning_results.append(result)\n",
    "                        \n",
    "                        # Save the model if this run achieved the best validation loss so far.\n",
    "                        if final_val_loss < best_val_loss:\n",
    "                            best_val_loss = final_val_loss\n",
    "                            best_params = result\n",
    "                            best_model_state = model.state_dict()\n",
    "                            # Create a model filename that includes the hyperparameters and validation loss.\n",
    "                            # model_filename = f\"gaitgen_6d_newnorm_hs{hs}_lr{lr}_bs{bs}_epochs{num_epochs}_val{final_val_loss:.4f}.pth\"\n",
    "                            # torch.save(model.state_dict(), os.path.join(results_dir, model_filename))\n",
    "                            # print(f\"  New best model saved as {os.path.join(results_dir, model_filename)}\")\n",
    "\n",
    "                # (Optional) Save a plot of train/val losses for this hyperparameter setting.\n",
    "                plt.figure()\n",
    "                plt.plot(np.arange(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "                plt.plot(np.linspace(10, num_epochs,num =len(val_losses)), val_losses, label='Val Loss')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.legend()\n",
    "                plt.title(f\"bs={bs}, hs={hs}, epochs={num_epochs}, lr={lr}\")\n",
    "                plt.tight_layout()\n",
    "                plot_filename = f\"loss_plot_bs{bs}_hs{hs}_epochs{num_epochs}_lr{lr}.png\"\n",
    "                plt.savefig(os.path.join(results_dir, plot_filename))\n",
    "                plt.close()\n",
    "                print(f\" Loss plot saved as {os.path.join(results_dir, plot_filename)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning is already completed no need to run the following cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(tuning_results)\n",
    "results_df_filename = os.path.join(results_dir, \"gaitgen_6d_newnorm.csv\")\n",
    "results_df.to_csv(results_df_filename, index=False)\n",
    "print(\"Hyperparameter tuning complete.\")\n",
    "print(\"Best hyperparameters:\")\n",
    "print(best_params)\n",
    "print(f\"Best model validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Tuning results saved to {results_df_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 200/10000 | Train Loss: 0.0222\n",
      "  Epoch 400/10000 | Train Loss: 0.0202\n",
      "  Epoch 600/10000 | Train Loss: 0.0190\n",
      "  Epoch 800/10000 | Train Loss: 0.0185\n",
      "  Epoch 1000/10000 | Train Loss: 0.0178\n",
      "  Epoch 1200/10000 | Train Loss: 0.0176\n",
      "  Epoch 1400/10000 | Train Loss: 0.0177\n",
      "  Epoch 1600/10000 | Train Loss: 0.0170\n",
      "  Epoch 1800/10000 | Train Loss: 0.0169\n",
      "  Epoch 2000/10000 | Train Loss: 0.0169\n",
      "  Epoch 2200/10000 | Train Loss: 0.0161\n",
      "  Epoch 2400/10000 | Train Loss: 0.0165\n",
      "  Epoch 2600/10000 | Train Loss: 0.0162\n",
      "  Epoch 2800/10000 | Train Loss: 0.0163\n",
      "  Epoch 3000/10000 | Train Loss: 0.0161\n",
      "  Epoch 3200/10000 | Train Loss: 0.0156\n",
      "  Epoch 3400/10000 | Train Loss: 0.0159\n",
      "  Epoch 3600/10000 | Train Loss: 0.0155\n",
      "  Epoch 3800/10000 | Train Loss: 0.0158\n",
      "  Epoch 4000/10000 | Train Loss: 0.0156\n",
      "  Epoch 4200/10000 | Train Loss: 0.0157\n",
      "  Epoch 4400/10000 | Train Loss: 0.0153\n",
      "  Epoch 4600/10000 | Train Loss: 0.0156\n",
      "  Epoch 4800/10000 | Train Loss: 0.0155\n",
      "  Epoch 5000/10000 | Train Loss: 0.0156\n",
      "  Epoch 5200/10000 | Train Loss: 0.0155\n",
      "  Epoch 5400/10000 | Train Loss: 0.0151\n",
      "  Epoch 5600/10000 | Train Loss: 0.0154\n",
      "  Epoch 5800/10000 | Train Loss: 0.0154\n",
      "  Epoch 6000/10000 | Train Loss: 0.0153\n",
      "  Epoch 6200/10000 | Train Loss: 0.0151\n",
      "  Epoch 6400/10000 | Train Loss: 0.0154\n",
      "  Epoch 6600/10000 | Train Loss: 0.0155\n",
      "  Epoch 6800/10000 | Train Loss: 0.0152\n",
      "  Epoch 7000/10000 | Train Loss: 0.0152\n",
      "  Epoch 7200/10000 | Train Loss: 0.0150\n",
      "  Epoch 7400/10000 | Train Loss: 0.0148\n",
      "  Epoch 7600/10000 | Train Loss: 0.0147\n",
      "  Epoch 7800/10000 | Train Loss: 0.0147\n",
      "  Epoch 8000/10000 | Train Loss: 0.0148\n",
      "  Epoch 8200/10000 | Train Loss: 0.0149\n",
      "  Epoch 8400/10000 | Train Loss: 0.0147\n",
      "  Epoch 8600/10000 | Train Loss: 0.0147\n",
      "  Epoch 8800/10000 | Train Loss: 0.0146\n",
      "  Epoch 9000/10000 | Train Loss: 0.0148\n",
      "  Epoch 9200/10000 | Train Loss: 0.0145\n",
      "  Epoch 9400/10000 | Train Loss: 0.0150\n",
      "  Epoch 9600/10000 | Train Loss: 0.0141\n",
      "  Epoch 9800/10000 | Train Loss: 0.0144\n",
      "  Epoch 10000/10000 | Train Loss: 0.0145\n"
     ]
    }
   ],
   "source": [
    "inputs = np.load(rf\"gait reference fft5.00/newnormalized_input_vector.npy\")\n",
    "outputs = np.load(rf\"gait reference fft5.00/newnormalized_output_fft_constants.npy\")\n",
    "\n",
    "outputs = outputs.transpose(0,2,3,1)\n",
    "outputs = torch.tensor(outputs, dtype=torch.float32)\n",
    "outputs = outputs.reshape(outputs.shape[0],-1)\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "train_data = TensorDataset(inputs, outputs)\n",
    "\n",
    "bs = best_params['batch_size']\n",
    "hs = best_params['hidden_size']\n",
    "lr = best_params['learning_rate']\n",
    "train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "\n",
    "num_epochs = 10000\n",
    "torch.manual_seed(23)  # Ensure reproducibility per run.\n",
    "model = SimpleFCNN(input_size=input_size, output_size=output_size, hidden_size=hs)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = CustomWeightedMSELoss()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop for the current hyperparameter combination.\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        # Ensure targets are the right shape.\n",
    "        targets = targets.view(-1, output_size)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item() * inputs.size(0)\n",
    "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    if (epoch+1) % 200 == 0 or epoch == num_epochs - 1:\n",
    "        print(f\"  Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_train_loss:.4f}\")\n",
    "\n",
    "model_filename = f\"newnorm_final_hs{hs}_lr{lr}_bs{bs}_epochs{num_epochs}.pth\"\n",
    "torch.save(model.state_dict(), os.path.join(model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "plots saved\n",
      "Test Loss: 0.0157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7c0d7c7da5f0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a test dataset and DataLoader\n",
    "test_dataloader = DataLoader(val_data, batch_size=1, shuffle=False)  # Batch size of 5\n",
    "norm_consts = np.load(rf\"gait reference fft5.00/newnormalization_constants.npy\")\n",
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "k = 0\n",
    "with torch.no_grad():  # No need to compute gradients during testing\n",
    "    for inputs, targets in test_dataloader:\n",
    "        speed = inputs[0,0].item()*3\n",
    "        targets = targets.reshape(-1,136)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "        ground_truth = targets.reshape(-1,4,2,17)\n",
    "        predictions = outputs.reshape(-1,4,2,17)\n",
    "\n",
    "        predictions = predictions.detach().numpy()\n",
    "        predictions = predictions[0]\n",
    "        ground_truth = ground_truth.detach().numpy()\n",
    "        ground_truth = ground_truth[0]\n",
    "\n",
    "        predictions, ground_truth = denormalize(predictions,ground_truth,norm_consts)\n",
    "        pred_time,gt_time = pred_ifft(predictions,ground_truth,speed,norm_consts)\n",
    "        # animate_biped(pred_time,f\"predict_plots_25hs512_fft/{speed:.1f}ms.gif\")\n",
    "        # animate_biped(gt_time,f\"predict_plots_25hs512_fft/{speed:.1f}ms.gif\")\n",
    "        k+=1\n",
    "# Calculate average loss and accuracy\n",
    "test_loss /= len(test_dataloader)  # Average test loss\n",
    "\n",
    "\n",
    "# Print test results\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "plt.plot(targets[0].numpy())\n",
    "plt.plot(outputs[0].numpy())\n",
    "plt.legend(['Ground Truth', 'Predictions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biped_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
