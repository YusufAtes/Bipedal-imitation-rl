{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ezc3d import c3d\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def lowpass_filter_data(data, cutoff=4, fs=100, order=4):\n",
    "    \"\"\"\n",
    "    Apply a Butterworth lowpass filter to the data along each column.\n",
    "\n",
    "    Parameters:\n",
    "      data   : 2D NumPy array of shape (n, 5)\n",
    "      cutoff : Cutoff frequency in Hz (default is 4 Hz)\n",
    "      fs     : Original sampling frequency (default is 100 Hz)\n",
    "      order  : Order of the Butterworth filter (default is 4)\n",
    "    \n",
    "    Returns:\n",
    "      Filtered data as a NumPy array with the same shape as the input.\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs                  # Nyquist Frequency\n",
    "    normal_cutoff = cutoff / nyq    # Normalized cutoff frequency\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    # Use filtfilt to avoid phase shift.\n",
    "    filtered_data = filtfilt(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "def downsample(data, orig_rate=100, new_rate=10):\n",
    "    \"\"\"\n",
    "    Downsample the data from orig_rate to new_rate by taking every (orig_rate/new_rate)-th sample.\n",
    "    \n",
    "    Parameters:\n",
    "      data      : 2D NumPy array of shape (n, 5)\n",
    "      orig_rate : Original sampling frequency (Hz)\n",
    "      new_rate  : Desired sampling frequency (Hz)\n",
    "    \n",
    "    Returns:\n",
    "      Downsampled data.\n",
    "    \"\"\"\n",
    "    factor = orig_rate // new_rate\n",
    "    return data[::factor]\n",
    "\n",
    "def find_near_zero_blocks(data, tol=1e-2, min_gap=30):\n",
    "    \"\"\"\n",
    "    Identify the start indices of contiguous blocks where all 5 columns are near zero.\n",
    "    A new near-zero block is only accepted if it is at least 'min_gap' samples after the previous one.\n",
    "\n",
    "    Parameters:\n",
    "      data    : 2D NumPy array of shape (n, 5)\n",
    "      tol     : Tolerance to consider a value as zero (default is 1e-2)\n",
    "      min_gap : Minimum number of samples between consecutive near-zero blocks (default is 30)\n",
    "    \n",
    "    Returns:\n",
    "      A NumPy array of filtered start indices for near-zero blocks.\n",
    "    \"\"\"\n",
    "    # Create a boolean mask that is True when all 5 columns are nearly zero.\n",
    "    near_zero = np.all(np.abs(data[:,:4]) < tol, axis=0)\n",
    "    \n",
    "    # Compute differences to identify transitions from non-zero to near-zero.\n",
    "    diff = np.diff(near_zero.astype(int))\n",
    "    starts = np.where(near_zero == True)[0]   # +1 to point to the first True value in the block\n",
    "    \n",
    "    # If the very first sample is near zero, include index 0.\n",
    "    if near_zero[0]:\n",
    "        starts = np.insert(starts, 0, 0)\n",
    "    \n",
    "    # Filter out indices that are too close together.\n",
    "    filtered_starts = []\n",
    "    if len(starts) > 0:\n",
    "        filtered_starts.append(starts[0])\n",
    "        for idx in starts[1:]:\n",
    "            if idx - filtered_starts[-1] >= min_gap:\n",
    "                filtered_starts.append(idx)\n",
    "    \n",
    "    return np.array(filtered_starts)\n",
    "\n",
    "def find_cycle_boundaries(data, tol=1e-2, min_gap=30):\n",
    "    \"\"\"\n",
    "    Identify cycle boundaries in the periodic data. Here, a cycle is assumed to start at the first \n",
    "    near-zero block and end at the start of the next near-zero block that is at least 'min_gap' samples later.\n",
    "    \n",
    "    Parameters:\n",
    "      data    : 2D NumPy array (downsampled) of shape (n, 5)\n",
    "      tol     : Tolerance to consider a value as zero (default is 1e-2)\n",
    "      min_gap : Minimum number of samples between consecutive near-zero blocks (default is 30)\n",
    "    \n",
    "    Returns:\n",
    "      A tuple (cycle_start, cycle_stop) indicating the start and stop indices of one cycle.\n",
    "    \"\"\"\n",
    "    near_zero_starts = find_near_zero_blocks(data, tol, min_gap)\n",
    "    \n",
    "    if len(near_zero_starts) < 2:\n",
    "        raise ValueError(\"Not enough near-zero regions found to determine a cycle!\")\n",
    "    \n",
    "    cycle_start = near_zero_starts[0]\n",
    "    cycle_stop = near_zero_starts[1]\n",
    "    return cycle_start, cycle_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lowpass_filter(data, cutoff=5, fs=100, order=4):\n",
    "#     nyquist = 0.5 * fs\n",
    "#     normal_cutoff = cutoff / nyquist\n",
    "#     b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "#     y = filtfilt(b, a, data, axis=0)\n",
    "#     return y\n",
    "\n",
    "def extract_gait_cycle(c, gait_duration=3):\n",
    "\n",
    "    times = c[\"parameters\"][\"EVENT\"][\"TIMES\"]['value']\n",
    "    contexts = c[\"parameters\"][\"EVENT\"][\"CONTEXTS\"]['value']\n",
    "    labels = c[\"parameters\"][\"EVENT\"][\"LABELS\"]['value']\n",
    "    gait_points = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        if (labels[i] == \"Foot Strike1\") and (contexts[i] == \"Right\"):\n",
    "            gait_start = int(times[1,i]*100)\n",
    "        if (labels[i] == \"Foot Strike2\") and (contexts[i] == \"Right\"):\n",
    "            gait_end = int(times[1,i]*100+1)\n",
    "\n",
    "    trial_data = c['data']['points']\n",
    "    labels = c['parameters']['POINT']['LABELS']['value']\n",
    "\n",
    "    #[15,4,16,5,20,9]\n",
    "    r_ftc = labels.index(\"R_FTC\") if \"R_FTC\" in labels else RuntimeError(\"R_FTC not found\")\n",
    "    l_ftc = labels.index(\"L_FTC\") if \"L_FTC\" in labels else RuntimeError(\"L_FTC not found\")\n",
    "    r_fle = labels.index(\"R_FLE\") if \"R_FLE\" in labels else RuntimeError(\"R_FLE not found\")\n",
    "    l_fle = labels.index(\"L_FLE\") if \"L_FLE\" in labels else RuntimeError(\"L_FLE not found\")\n",
    "    r_fal = labels.index(\"R_FAL\") if \"R_FAL\" in labels else RuntimeError(\"R_FAL not found\")\n",
    "    l_fal = labels.index(\"L_FAL\") if \"L_FAL\" in labels else RuntimeError(\"L_FAL not found\")\n",
    "    r_fcc = labels.index(\"R_FCC\") if \"R_FCC\" in labels else RuntimeError(\"R_FCC not found\")\n",
    "    r_fm1 = labels.index(\"R_FM1\") if \"R_FM1\" in labels else RuntimeError(\"R_FM1 not found\")\n",
    "    l_fcc = labels.index(\"L_FCC\") if \"L_FCC\" in labels else RuntimeError(\"L_FCC not found\")\n",
    "    l_fm1 = labels.index(\"L_FM1\") if \"L_FM1\" in labels else RuntimeError(\"L_FM1 not found\")\n",
    "\n",
    "    sjn = labels.index(\"SJN\") if \"SJN\" in labels else RuntimeError(\"SJN not found\")\n",
    "    sxs = labels.index(\"SXS\") if \"SXS\" in labels else RuntimeError(\"SXS not found\")\n",
    "\n",
    "    r_leglength_ind = c['parameters']['SUBJECT']['LABELS']['value'].index(\"R_legLength\") if \"R_legLength\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"R_LEGLENGTH not found\")\n",
    "    l_leglength_ind = c['parameters']['SUBJECT']['LABELS']['value'].index(\"L_legLength\") if \"L_legLength\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"L_LEGLENGTH not found\")\n",
    "    weight = c['parameters']['SUBJECT']['LABELS']['value'].index(\"weight\") if \"weight\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"Weight not found\")\n",
    "    height = c['parameters']['SUBJECT']['LABELS']['value'].index(\"height\") if \"height\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"Height not found\")\n",
    "    r_leglength = c['parameters']['SUBJECT']['VALUES']['value'][r_leglength_ind]\n",
    "    l_leglength = c['parameters']['SUBJECT']['VALUES']['value'][l_leglength_ind]\n",
    "    weight = c['parameters']['SUBJECT']['VALUES']['value'][weight]\n",
    "    height = c['parameters']['SUBJECT']['VALUES']['value'][height]\n",
    "\n",
    "    muscle_index = [r_ftc,l_ftc,r_fle,l_fle,r_fal,l_fal,sxs,sjn,r_fcc,r_fm1,l_fcc,l_fm1]\n",
    "    joint_data = trial_data[:,muscle_index,:]\n",
    "    joint_states = np.zeros((joint_data.shape[2],6))\n",
    "\n",
    "    data_len = joint_data.shape[2]\n",
    "\n",
    "    first_pos = trial_data[0,sxs,0]\n",
    "    last_pos = trial_data[0,sxs,-1]\n",
    "\n",
    "    if last_pos > first_pos:\n",
    "        forward_walk = True\n",
    "    else:\n",
    "        forward_walk = False\n",
    "\n",
    "    speed_muscle = trial_data[:,sxs,:]\n",
    "    speed = (np.abs(speed_muscle[0,-1]-speed_muscle[0,0])/(len(speed_muscle[0,:])))/10\n",
    "    #data_point[:,-1] = speed\n",
    "\n",
    "    if forward_walk:\n",
    "        for i in range(data_len):\n",
    "            joint_states[i,0] = np.arctan2((joint_data[0,2,i] - joint_data[0,0,i])   , (-joint_data[2,2,i] + joint_data[2,0,i])) \n",
    "            joint_states[i,1] = np.arctan2((joint_data[0,4,i] - joint_data[0,2,i])   , (-joint_data[2,4,i] + joint_data[2,2,i]))  - joint_states[i,0]\n",
    "            joint_states[i,2] = np.arctan2((joint_data[2,9,i] - joint_data[2,8,i])   , (joint_data[0,9,i] - joint_data[0,8,i]))   - joint_states[i,0] - joint_states[i,1]\n",
    "            joint_states[i,3] = np.arctan2((joint_data[0,3,i] - joint_data[0,1,i])   , (-joint_data[2,3,i] + joint_data[2,1,i]))\n",
    "            joint_states[i,4] = np.arctan2((joint_data[0,5,i] - joint_data[0,3,i])   , (-joint_data[2,5,i] + joint_data[2,3,i]))  - joint_states[i,3]\n",
    "            joint_states[i,5] = np.arctan2((joint_data[2,11,i] - joint_data[2,10,i]) , (joint_data[0,11,i] - joint_data[0,10,i])) - joint_states[i,3] - joint_states[i,4]\n",
    "\n",
    "    else:\n",
    "        for i in range(data_len):\n",
    "            joint_states[i,0] = np.arctan2((-joint_data[0,2,i] + joint_data[0,0,i]) , (-joint_data[2,2,i] + joint_data[2,0,i])) \n",
    "            joint_states[i,1] = np.arctan2((-joint_data[0,4,i] + joint_data[0,2,i]) , (-joint_data[2,4,i] + joint_data[2,2,i]))     - joint_states[i,0]\n",
    "            joint_states[i,2] = np.arctan2((joint_data[2,9,i] - joint_data[2,8,i])   ,(-joint_data[0,9,i] + joint_data[0,8,i]))     - joint_states[i,0] - joint_states[i,1]\n",
    "            joint_states[i,3] = np.arctan2((-joint_data[0,3,i] + joint_data[0,1,i]) , (-joint_data[2,3,i] + joint_data[2,1,i]))\n",
    "            joint_states[i,4] = np.arctan2((-joint_data[0,5,i] + joint_data[0,3,i]) , (-joint_data[2,5,i] + joint_data[2,3,i]))     - joint_states[i,3]\n",
    "            joint_states[i,5] = np.arctan2((joint_data[2,11,i] - joint_data[2,10,i]) ,(-joint_data[0,11,i] + joint_data[0,10,i]))   - joint_states[i,3] - joint_states[i,4]\n",
    "\n",
    "\n",
    "    total_gait_sample = 32\n",
    "    joint_states = lowpass_filter_data(joint_states)\n",
    "    # gait_start, gait_end = find_cycle_boundaries(joint_states, tol=1e-1, min_gap=30)\n",
    "    joint_states = joint_states[gait_start:gait_end,:]\n",
    "    joint_states = downsample(joint_states, orig_rate=100, new_rate=10)\n",
    "    if joint_states.shape[0] > total_gait_sample:\n",
    "        print(f'gait cycle: {joint_states.shape[1]} longer than {gait_duration} seconds')\n",
    "        \n",
    "    while joint_states.shape[0] < total_gait_sample:\n",
    "        joint_states = np.concatenate((joint_states, joint_states),axis=0)  # Stack horizontally\n",
    "\n",
    "    joint_states = joint_states[:total_gait_sample,:]\n",
    "    # padded_joint_states = np.zeros((512, 4))\n",
    "    # padded_joint_states[46:46+joint_states.shape[0],:] = joint_states\n",
    "    \n",
    "    joint_states_rfft = np.fft.rfft(joint_states, n=32,axis=0)\n",
    "    real_fft = np.real(joint_states_rfft)\n",
    "    imag_fft = np.imag(joint_states_rfft)\n",
    "    joint_states_rfft = np.stack((real_fft, imag_fft), axis=2)\n",
    "    freq_values = np.fft.rfftfreq(32, 1/10)\n",
    "    encoder_vec = np.empty((3))   # init_pos + speed + r_leglength + l_leglength + ramp_angle = 0\n",
    "    # encoder_vec[0:4] = joint_states[:,0]\n",
    "    encoder_vec[0] = speed/3\n",
    "    encoder_vec[1] = r_leglength /1.5\n",
    "    encoder_vec[2] = l_leglength /1.5\n",
    "    # encoder_vec[3] = weight / 100  # 100 is the maximum weight in the dataset\n",
    "    # encoder_vec[4] = height / 2    # 1.91 m is the maximum height in the dataset\n",
    "\n",
    "    encoder_vec = encoder_vec[np.newaxis, :]\n",
    "    joint_states_rfft = joint_states_rfft[np.newaxis, :, :] #179 is the maximum value in the dataset\n",
    "    return joint_states_rfft, freq_values, encoder_vec, joint_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gait_duration = 2\n",
    "folders = [d for d in os.listdir(os.path.join(os.getcwd(),'dataset')) if os.path.isdir(os.path.join(os.path.join(os.getcwd(),'dataset'), d))]\n",
    "k=0\n",
    "if os.path.exists(f\"gait reference fft_plots_\") == False:\n",
    "    os.mkdir(f\"gait reference fft_plots_\")\n",
    "\n",
    "for folder in folders:\n",
    "    folder_len = len(folder)\n",
    "    files = [f for f in os.listdir(os.path.join(os.getcwd(),'dataset',folder)) if f.endswith('.c3d')]\n",
    "    \n",
    "    print(f\"{k}/{len(folders)} is processed current folder is {folder}\") \n",
    "    i = 0\n",
    "    for file in files:\n",
    "        if 'ST' not in file:\n",
    "            c = c3d(os.path.join('dataset',folder,file))\n",
    "            joint_states_rfft, freq_values, encoder_vec, joint_states = extract_gait_cycle(c,gait_duration=gait_duration)\n",
    "            # if np.max(np.abs(joint_states)) > 1:\n",
    "            #     print(f'joint_states max value is greater than 1 in {folder}_{file[:-4]}')\n",
    "            #     break\n",
    "            if i == 0:\n",
    "                folder_output_state = joint_states_rfft\n",
    "                folder_input_vector = encoder_vec\n",
    "            else:\n",
    "                folder_output_state = np.vstack((folder_output_state,joint_states_rfft))\n",
    "                folder_input_vector = np.vstack((folder_input_vector,encoder_vec))\n",
    "            i+=1\n",
    "    print('folder_output_state_shape: ',folder_output_state.shape)\n",
    "    print('folder input vector shape: ',folder_input_vector.shape)\n",
    "    print('-----------------------------------')\n",
    "    if k == 0:\n",
    "        total_output_state = folder_output_state\n",
    "        total_input_vector = folder_input_vector\n",
    "    else:\n",
    "        total_output_state = np.vstack((total_output_state,folder_output_state))\n",
    "        total_input_vector = np.vstack((total_input_vector,folder_input_vector))\n",
    "    k+=1\n",
    "#     np.save(f\"ref_gait_library_duration{gait_duration}/{folder}_output_state.npy\",folder_output_state)\n",
    "#     np.save(f\"ref_gait_library_duration{gait_duration}/{folder}_input_vector.npy\",folder_input_vector)\n",
    "\n",
    "if os.path.exists(f\"gait reference fft{freq_values[-1]:.2f}\") == False:\n",
    "    os.mkdir(f\"gait reference fft{freq_values[-1]:.2f}\")\n",
    "\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/output_fft_constants.npy\",total_output_state)\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/input_vector.npy\",total_input_vector)\n",
    "\n",
    "print('total output state ',total_output_state.shape)\n",
    "print('total input vector ',total_input_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(np.abs(total_input_vector[:,0])))  # speed\n",
    "print(np.max(np.abs(total_input_vector[:,1])))  # r_leglength\n",
    "print(np.max(np.abs(total_input_vector[:,2])))  # l_leglength\n",
    "\n",
    "print(total_output_state.shape)                 #shape of the vector\n",
    "\n",
    "r1_coeff = np.max(np.abs(total_output_state[:,0,:,0]))\n",
    "i1_coeff = np.max(np.abs(total_output_state[:,0,:,1]))\n",
    "r2_coeff = np.max(np.abs(total_output_state[:,1,:,0]))\n",
    "i2_coeff = np.max(np.abs(total_output_state[:,1,:,1]))\n",
    "r3_coeff = np.max(np.abs(total_output_state[:,2,:,0]))\n",
    "i3_coeff = np.max(np.abs(total_output_state[:,2,:,1]))\n",
    "r4_coeff = np.max(np.abs(total_output_state[:,3,:,0]))\n",
    "i4_coeff = np.max(np.abs(total_output_state[:,3,:,1]))\n",
    "r5_coeff = np.max(np.abs(total_output_state[:,4,:,0]))\n",
    "i5_coeff = np.max(np.abs(total_output_state[:,4,:,1]))\n",
    "r6_coeff = np.max(np.abs(total_output_state[:,5,:,0]))\n",
    "i6_coeff = np.max(np.abs(total_output_state[:,5,:,1]))\n",
    "r7_coeff = np.max(np.abs(total_output_state[:,6,:,0]))\n",
    "i7_coeff = np.max(np.abs(total_output_state[:,6,:,1]))\n",
    "r8_coeff = np.max(np.abs(total_output_state[:,7,:,0]))\n",
    "i8_coeff = np.max(np.abs(total_output_state[:,7,:,1]))\n",
    "r9_coeff = np.max(np.abs(total_output_state[:,8,:,0]))\n",
    "i9_coeff = np.max(np.abs(total_output_state[:,8,:,1]))\n",
    "r10_coeff = np.max(np.abs(total_output_state[:,9,:,0]))\n",
    "i10_coeff = np.max(np.abs(total_output_state[:,9,:,1]))\n",
    "r11_coeff = np.max(np.abs(total_output_state[:,10,:,0]))\n",
    "i11_coeff = np.max(np.abs(total_output_state[:,10,:,1]))\n",
    "r12_coeff = np.max(np.abs(total_output_state[:,11,:,0]))\n",
    "i12_coeff = np.max(np.abs(total_output_state[:,11,:,1]))\n",
    "r13_coeff = np.max(np.abs(total_output_state[:,12,:,0]))\n",
    "i13_coeff = np.max(np.abs(total_output_state[:,12,:,1]))\n",
    "r14_coeff = np.max(np.abs(total_output_state[:,13,:,0]))\n",
    "i14_coeff = np.max(np.abs(total_output_state[:,13,:,1]))\n",
    "r15_coeff = np.max(np.abs(total_output_state[:,14,:,0]))\n",
    "i15_coeff = np.max(np.abs(total_output_state[:,14,:,1]))\n",
    "r16_coeff = np.max(np.abs(total_output_state[:,15,:,0]))\n",
    "i16_coeff = np.max(np.abs(total_output_state[:,15,:,1]))\n",
    "r17_coeff = np.max(np.abs(total_output_state[:,16,:,0]))\n",
    "i17_coeff = np.max(np.abs(total_output_state[:,16,:,1]))\n",
    "\n",
    "print(f'r1_coeff: {r1_coeff} i1_coeff: {i1_coeff}')\n",
    "print(f'r2_coeff: {r2_coeff} i2_coeff: {i2_coeff}')\n",
    "print(f'r3_coeff: {r3_coeff} i3_coeff: {i3_coeff}')\n",
    "print(f'r4_coeff: {r4_coeff} i4_coeff: {i4_coeff}')\n",
    "print(f'r5_coeff: {r5_coeff} i5_coeff: {i5_coeff}')\n",
    "print(f'r6_coeff: {r6_coeff} i6_coeff: {i6_coeff}')\n",
    "print(f'r7_coeff: {r7_coeff} i7_coeff: {i7_coeff}')\n",
    "print(f'r8_coeff: {r8_coeff} i8_coeff: {i8_coeff}')\n",
    "print(f'r9_coeff: {r9_coeff} i9_coeff: {i9_coeff}')\n",
    "print(f'r10_coeff: {r10_coeff} i10_coeff: {i10_coeff}')\n",
    "print(f'r11_coeff: {r11_coeff} i11_coeff: {i11_coeff}')\n",
    "print(f'r12_coeff: {r12_coeff} i12_coeff: {i12_coeff}')\n",
    "print(f'r13_coeff: {r13_coeff} i13_coeff: {i13_coeff}')\n",
    "print(f'r14_coeff: {r14_coeff} i14_coeff: {i14_coeff}')\n",
    "print(f'r15_coeff: {r15_coeff} i15_coeff: {i15_coeff}')\n",
    "print(f'r16_coeff: {r16_coeff} i16_coeff: {i16_coeff}')\n",
    "print(f'r17_coeff: {r17_coeff} i17_coeff: {i17_coeff}')\n",
    "\n",
    "total_output_state[:,0,:,0] = total_output_state[:,0,:,0]/r1_coeff\n",
    "total_output_state[:,0,:,1] = total_output_state[:,0,:,1]\n",
    "total_output_state[:,1,:,0] = total_output_state[:,1,:,0]/r2_coeff\n",
    "total_output_state[:,1,:,1] = total_output_state[:,1,:,1]/i2_coeff\n",
    "total_output_state[:,2,:,0] = total_output_state[:,2,:,0]/r3_coeff\n",
    "total_output_state[:,2,:,1] = total_output_state[:,2,:,1]/i3_coeff\n",
    "total_output_state[:,3,:,0] = total_output_state[:,3,:,0]/r4_coeff\n",
    "total_output_state[:,3,:,1] = total_output_state[:,3,:,1]/i4_coeff\n",
    "total_output_state[:,4,:,0] = total_output_state[:,4,:,0]/r5_coeff\n",
    "total_output_state[:,4,:,1] = total_output_state[:,4,:,1]/i5_coeff\n",
    "total_output_state[:,5,:,0] = total_output_state[:,5,:,0]/r6_coeff\n",
    "total_output_state[:,5,:,1] = total_output_state[:,5,:,1]/i6_coeff\n",
    "total_output_state[:,6,:,0] = total_output_state[:,6,:,0]/r7_coeff\n",
    "total_output_state[:,6,:,1] = total_output_state[:,6,:,1]/i7_coeff\n",
    "total_output_state[:,7,:,0] = total_output_state[:,7,:,0]/r8_coeff\n",
    "total_output_state[:,7,:,1] = total_output_state[:,7,:,1]/i8_coeff\n",
    "total_output_state[:,8,:,0] = total_output_state[:,8,:,0]/r9_coeff\n",
    "total_output_state[:,8,:,1] = total_output_state[:,8,:,1]/i9_coeff\n",
    "total_output_state[:,9,:,0] = total_output_state[:,9,:,0]/r10_coeff\n",
    "total_output_state[:,9,:,1] = total_output_state[:,9,:,1]/i10_coeff\n",
    "total_output_state[:,10,:,0] = total_output_state[:,10,:,0]/r11_coeff\n",
    "total_output_state[:,10,:,1] = total_output_state[:,10,:,1]/i11_coeff\n",
    "total_output_state[:,11,:,0] = total_output_state[:,11,:,0]/r12_coeff\n",
    "total_output_state[:,11,:,1] = total_output_state[:,11,:,1]/i12_coeff\n",
    "total_output_state[:,12,:,0] = total_output_state[:,12,:,0]/r13_coeff\n",
    "total_output_state[:,12,:,1] = total_output_state[:,12,:,1]/i13_coeff\n",
    "total_output_state[:,13,:,0] = total_output_state[:,13,:,0]/r14_coeff\n",
    "total_output_state[:,13,:,1] = total_output_state[:,13,:,1]/i14_coeff\n",
    "total_output_state[:,14,:,0] = total_output_state[:,14,:,0]/r15_coeff\n",
    "total_output_state[:,14,:,1] = total_output_state[:,14,:,1]/i15_coeff\n",
    "total_output_state[:,15,:,0] = total_output_state[:,15,:,0]/r16_coeff\n",
    "total_output_state[:,15,:,1] = total_output_state[:,15,:,1]/i16_coeff\n",
    "total_output_state[:,16,:,0] = total_output_state[:,16,:,0]/r17_coeff\n",
    "total_output_state[:,16,:,1] = total_output_state[:,16,:,1]\n",
    "\n",
    "\n",
    "#i1 and i17 is zero for all the data points\n",
    "normalizationconst = [r1_coeff,i1_coeff,r2_coeff,i2_coeff,r3_coeff,i3_coeff,r4_coeff,i4_coeff,r5_coeff,i5_coeff,r6_coeff,i6_coeff,r7_coeff,i7_coeff,r8_coeff,i8_coeff,r9_coeff,i9_coeff,r10_coeff,i10_coeff,r11_coeff,i11_coeff,r12_coeff,i12_coeff,r13_coeff,i13_coeff,r14_coeff,i14_coeff,r15_coeff,i15_coeff,r16_coeff,i16_coeff,r17_coeff,i17_coeff]\n",
    "\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/newnormalized_output_fft_constants.npy\",total_output_state)\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/newnormalized_input_vector.npy\",total_input_vector)\n",
    "np.save(f\"gait reference fft{freq_values[-1]:.2f}/newnormalization_constants.npy\",normalizationconst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Old Way of Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NORMALIZATION OF THE DATA IS IMPLEMENTED\n",
    "# import numpy as np\n",
    "# real_rthigh = np.max(np.abs(total_output_state[:,:,0,0]))\n",
    "# imag_rthigh = np.max(np.abs(total_output_state[:,:,0,1]))\n",
    "\n",
    "# real_rshank = np.max(np.abs(total_output_state[:,:,1,0]))\n",
    "# imag_rshank = np.max(np.abs(total_output_state[:,:,1,1]))\n",
    "\n",
    "# real_lthigh = np.max(np.abs(total_output_state[:,:,2,0]))\n",
    "# imag_lthigh = np.max(np.abs(total_output_state[:,:,2,1]))\n",
    "\n",
    "# real_lshank = np.max(np.abs(total_output_state[:,:,3,0]))\n",
    "# imag_lshank = np.max(np.abs(total_output_state[:,:,3,1]))\n",
    "\n",
    "# print(real_rthigh,imag_rthigh,real_rshank,imag_rshank,real_lthigh,imag_lthigh,real_lshank,imag_lshank)\n",
    "\n",
    "# normalizationconst = np.array([real_rthigh,imag_rthigh,real_rshank,imag_rshank,real_lthigh,imag_lthigh,real_lshank,imag_lshank])\n",
    "\n",
    "# total_output_state[:,:,0,0] = total_output_state[:,:,0,0] / real_rthigh\n",
    "# total_output_state[:,:,1,0] = total_output_state[:,:,1,0] / real_rshank\n",
    "# total_output_state[:,:,2,0] = total_output_state[:,:,2,0] / real_lthigh\n",
    "# total_output_state[:,:,3,0] = total_output_state[:,:,3,0] / real_lshank\n",
    "\n",
    "# total_output_state[:,:,0,1] = total_output_state[:,:,0,1] / imag_rthigh\n",
    "# total_output_state[:,:,1,1] = total_output_state[:,:,1,1] / imag_rshank\n",
    "# total_output_state[:,:,2,1] = total_output_state[:,:,2,1] / imag_lthigh\n",
    "# total_output_state[:,:,3,1] = total_output_state[:,:,3,1] / imag_lshank\n",
    "\n",
    "# np.save(f\"gait reference fft{freq_values[-1]:.2f}/oldnormalized_output_fft_constants.npy\",total_output_state)\n",
    "# np.save(f\"gait reference fft{freq_values[-1]:.2f}/oldnormalized_input_vector.npy\",total_input_vector)\n",
    "# np.save(f\"gait reference fft{freq_values[-1]:.2f}/oldnormalization_constants.npy\",normalizationconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_ifft_plots(joint_states_rfft,joint_states,frequencies,path,crop_ind=30):\n",
    "#     frequency = frequencies[crop_ind]\n",
    "#     joint_states_rfft = 180*np.squeeze(joint_states_rfft)\n",
    "#     cropped = joint_states_rfft.copy()\n",
    "#     cropped[crop_ind:,:] = 0\n",
    "#     ifft = np.fft.irfft(cropped, axis=0)\n",
    "#     cropped_ifft = ifft[56:-56,:]\n",
    "#     fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "#     axs[0, 0].plot(joint_states[:,0])\n",
    "#     axs[0, 0].plot(cropped_ifft[:,0])\n",
    "#     axs[0, 0].legend(['Original', 'Reconstructed'])\n",
    "#     axs[0, 0].set_title('Right Shank')\n",
    "#     axs[0, 1].plot(joint_states[:,1])\n",
    "#     axs[0, 1].plot(cropped_ifft[:,1])\n",
    "#     axs[0, 1].set_title('Right Thigh')\n",
    "#     axs[0, 1].legend(['Original', 'Reconstructed'])\n",
    "#     axs[1, 0].plot(joint_states[:,2])\n",
    "#     axs[1, 0].plot(cropped_ifft[:,2])\n",
    "#     axs[1, 0].set_title('Left Shank')\n",
    "#     axs[1, 0].legend(['Original', 'Reconstructed'])\n",
    "#     axs[1, 1].plot(joint_states[:,3])\n",
    "#     axs[1, 1].plot(cropped_ifft[:,3])\n",
    "#     axs[1, 1].set_title('Left Thigh')\n",
    "#     axs[1, 1].legend(['Original', 'Reconstructed'])\n",
    "#     plt.savefig(path+'.png')\n",
    "#     plt.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "train_for = \"normal\"\n",
    "\n",
    "inputs = np.load(rf\"gait reference fft5.00/newnormalized_input_vector.npy\")\n",
    "outputs = np.load(rf\"gait reference fft5.00/newnormalized_output_fft_constants.npy\")\n",
    "\n",
    "#train test split using sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.1, random_state=23)\n",
    "\n",
    "y_train = y_train\n",
    "y_train  = y_train.transpose(0,2,3,1)\n",
    "if train_for == \"taga\":\n",
    "    y_train = y_train[:,:4,:,:]\n",
    "print(y_train.shape)\n",
    "y_train = y_train.reshape(y_train.shape[0],-1)\n",
    "y_test = y_test\n",
    "y_test = y_test.transpose(0,2,3,1)\n",
    "if train_for == \"taga\":\n",
    "    y_test = y_test[:,:4,:,:]\n",
    "print(y_test.shape)\n",
    "y_test = y_test.reshape(y_test.shape[0],-1)\n",
    "#convert to tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# create dataloader\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "val_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "print('train data shape: ',X_train.shape)\n",
    "print('test data shape: ',X_test.shape)\n",
    "print('train output shape: ',y_train.shape)\n",
    "print('test output shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New Normalize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(pred,gt,normalizationconst):\n",
    "    #form is [5,2,17]\n",
    "    for i in range(17):\n",
    "        for k in range(2):\n",
    "            pred[:,k,i] = pred[:,k,i] * normalizationconst[i*2+k]\n",
    "            gt[:,k,i] = gt[:,k,i] * normalizationconst[i*2+k]\n",
    "    \n",
    "    return pred,gt\n",
    "\n",
    "def pred_ifft(predictions,ground_truth,speed,normalizationconst):\n",
    "    #form is [5,2,17]\n",
    "    real_pred = predictions[:,0,:]\n",
    "    imag_pred = predictions[:,1,:]\n",
    "    predictions = real_pred + 1j*imag_pred\n",
    "    real_gt = ground_truth[:,0,:]\n",
    "    imag_gt = ground_truth[:,1,:]\n",
    "    ground_truth = real_gt + 1j*imag_gt\n",
    "    \n",
    "\n",
    "    pred_time = np.fft.irfft(predictions, axis=1)\n",
    "    gt_time = np.fft.irfft(ground_truth, axis=1)\n",
    "    pred_time = pred_time.transpose(1,0)\n",
    "    gt_time = gt_time.transpose(1,0)\n",
    "    #plot 2*2 subplots\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.plot(pred_time[:,0])\n",
    "    plt.plot(gt_time[:,0])\n",
    "    plt.title('Right Hip')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.plot(pred_time[:,1])\n",
    "    plt.plot(gt_time[:,1])\n",
    "    plt.title('Right Knee')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.plot(pred_time[:,2])\n",
    "    plt.plot(gt_time[:,2])\n",
    "    plt.title('Right Ankle')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.plot(pred_time[:,3])\n",
    "    plt.plot(gt_time[:,3])\n",
    "    plt.title('Left Hip')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.plot(pred_time[:,4])\n",
    "    plt.plot(gt_time[:,4])\n",
    "    plt.title('Left Knee')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.plot(pred_time[:,5])\n",
    "    plt.plot(gt_time[:,5])\n",
    "    plt.title('Left Ankle')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "\n",
    "    plt.savefig(f\"compare/newankle{speed:.2f}ms.png\")\n",
    "    plt.close()\n",
    "    print('plots saved')\n",
    "    return pred_time,gt_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Old Denormalize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def denormalize(pred,gt,normalizationconst):\n",
    "#     #form is [5,2,17]\n",
    "#     pred[0,0,:] = pred[0,0,:] * normalizationconst[0]\n",
    "#     pred[0,1,:] = pred[0,1,:] * normalizationconst[1]\n",
    "#     pred[1,0,:] = pred[1,0,:] * normalizationconst[2]\n",
    "#     pred[1,1,:] = pred[1,1,:] * normalizationconst[3]\n",
    "#     pred[2,0,:] = pred[2,0,:] * normalizationconst[4]\n",
    "#     pred[2,1,:] = pred[2,1,:] * normalizationconst[5]\n",
    "#     pred[3,0,:] = pred[3,0,:] * normalizationconst[6]\n",
    "#     pred[3,1,:] = pred[3,1,:] * normalizationconst[7]\n",
    "\n",
    "    \n",
    "\n",
    "#     gt[0,0,:] = gt[0,0,:] * normalizationconst[0]\n",
    "#     gt[0,1,:] = gt[0,1,:] * normalizationconst[1]\n",
    "#     gt[1,0,:] = gt[1,0,:] * normalizationconst[2]\n",
    "#     gt[1,1,:] = gt[1,1,:] * normalizationconst[3]\n",
    "#     gt[2,0,:] = gt[2,0,:] * normalizationconst[4]\n",
    "#     gt[2,1,:] = gt[2,1,:] * normalizationconst[5]\n",
    "#     gt[3,0,:] = gt[3,0,:] * normalizationconst[6]\n",
    "#     gt[3,1,:] = gt[3,1,:] * normalizationconst[7]\n",
    "\n",
    "    \n",
    "#     return pred,gt\n",
    "    \n",
    "\n",
    "# def pred_ifft(predictions,ground_truth,speed,normalizationconst):\n",
    "#     #form is [5,2,17]\n",
    "#     real_pred = predictions[:,0,:]\n",
    "#     imag_pred = predictions[:,1,:]\n",
    "#     predictions = real_pred + 1j*imag_pred\n",
    "#     real_gt = ground_truth[:,0,:]\n",
    "#     imag_gt = ground_truth[:,1,:]\n",
    "#     ground_truth = real_gt + 1j*imag_gt\n",
    "    \n",
    "\n",
    "#     pred_time = np.fft.irfft(predictions, axis=1)\n",
    "#     gt_time = np.fft.irfft(ground_truth, axis=1)\n",
    "#     pred_time = pred_time.transpose(1,0)\n",
    "#     gt_time = gt_time.transpose(1,0)\n",
    "#     #plot 2*2 subplots\n",
    "#     plt.figure(figsize=(10,8))\n",
    "#     plt.subplot(2,2,1)\n",
    "#     plt.plot(pred_time[:,0])\n",
    "#     plt.plot(gt_time[:,0])\n",
    "#     plt.title('Right Hip')\n",
    "#     plt.legend(['Predicted','Ground Truth'])\n",
    "#     plt.subplot(2,2,2)\n",
    "#     plt.plot(pred_time[:,1])\n",
    "#     plt.plot(gt_time[:,1])\n",
    "#     plt.title('Right Knee')\n",
    "#     plt.legend(['Predicted','Ground Truth'])\n",
    "#     plt.subplot(2,2,3)\n",
    "#     plt.plot(pred_time[:,2])\n",
    "#     plt.plot(gt_time[:,2])\n",
    "#     plt.title('Left Hip')\n",
    "#     plt.legend(['Predicted','Ground Truth'])\n",
    "#     plt.subplot(2,2,4)\n",
    "#     plt.plot(pred_time[:,3])\n",
    "#     plt.plot(gt_time[:,3])\n",
    "#     plt.title('Left Knee')\n",
    "#     plt.legend(['Predicted','Ground Truth'])\n",
    "\n",
    "#     plt.savefig(f\"compare/oldankle_{speed:.2f}ms.png\")\n",
    "#     plt.close()\n",
    "#     print('plots saved')\n",
    "#     return pred_time,gt_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Create the results folder if it does not exist.\n",
    "# -----------------------------\n",
    "\n",
    "results_dir = \"ref_gait_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# # -----------------------------\n",
    "# # 1. Define Custom Loss Function\n",
    "# # -----------------------------\n",
    "# class CustomWeightedMSELoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomWeightedMSELoss, self).__init__()\n",
    "\n",
    "#     def forward(self, predictions, targets):\n",
    "#         # Compute element-wise squared error\n",
    "#         squared_error = (predictions - targets) ** 2\n",
    "#         # If the absolute prediction is larger than the absolute target, weight = 1.5; otherwise weight = 1.0.\n",
    "#         weights = torch.where(torch.abs(predictions) > torch.abs(targets),\n",
    "#                               torch.tensor(1.2, device=predictions.device),\n",
    "#                               torch.tensor(1.0, device=predictions.device))\n",
    "#         weighted_squared_error = weights * squared_error\n",
    "#         return torch.mean(weighted_squared_error)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Define Model Architecture\n",
    "# -----------------------------\n",
    "class SimpleFCNN(nn.Module):\n",
    "    def __init__(self, input_size=3, output_size=204, hidden_size=128):\n",
    "        super(SimpleFCNN, self).__init__()\n",
    "        # Layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [32,64]  # Different batch sizes to test\n",
    "hidden_sizes = [256,512]\n",
    "num_epochs_list = [8000]  # Number of epochs for training\n",
    "learning_rates = [1e-3,3e-4]\n",
    "input_size = 3\n",
    "output_size = 204\n",
    "\n",
    "torch.manual_seed(23)  # For reproducibility\n",
    "# This list will collect the results from each hyperparameter combination.\n",
    "tuning_results = []\n",
    "\n",
    "# Variables to store the best model and best validation loss\n",
    "best_val_loss = float('inf')\n",
    "best_params = None\n",
    "best_model_state = None\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Hyperparameter Tuning Loop\n",
    "# -----------------------------\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    # Create DataLoader for training and validation using the current batch size.\n",
    "    train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=bs, shuffle=False)\n",
    "    \n",
    "    for hs in hidden_sizes:\n",
    "        for num_epochs in num_epochs_list:\n",
    "            for lr in learning_rates:\n",
    "                print(f\"Training with batch_size={bs}, hidden_size={hs}, epochs={num_epochs}, lr={lr}\")\n",
    "                \n",
    "                # Initialize the model and optimizer for the current hyperparameters.\n",
    "                torch.manual_seed(23)  # Ensure reproducibility per run.\n",
    "                model = SimpleFCNN(input_size=input_size, output_size=output_size, hidden_size=hs)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "                loss_fn = nn.MSELoss()\n",
    "                \n",
    "                train_losses = []\n",
    "                val_losses = []\n",
    "                \n",
    "                # Training loop for the current hyperparameter combination.\n",
    "                for epoch in range(num_epochs):\n",
    "                    model.train()\n",
    "                    running_train_loss = 0.0\n",
    "                    for inputs, targets in train_loader:\n",
    "                        # Ensure targets are the right shape.\n",
    "                        targets = targets.view(-1, output_size)\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(inputs)\n",
    "                        loss = loss_fn(outputs, targets)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        running_train_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "                    train_losses.append(epoch_train_loss)\n",
    "\n",
    "                    # Optionally print progress every 10 epochs (or at the last epoch)\n",
    "                    if (epoch+1) % 200 == 0 or epoch == num_epochs - 1:\n",
    "                        # Validation loop\n",
    "                        model.eval()\n",
    "                        running_val_loss = 0.0\n",
    "                        with torch.no_grad():\n",
    "                            for inputs, targets in val_loader:\n",
    "                                targets = targets.view(-1, output_size)\n",
    "                                outputs = model(inputs)\n",
    "                                loss = loss_fn(outputs, targets)\n",
    "                                running_val_loss += loss.item() * inputs.size(0)\n",
    "                        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "                        val_losses.append(epoch_val_loss)\n",
    "                        print(f\"  Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_train_loss:.6f} | Val Loss: {epoch_val_loss:.6f}\")\n",
    "                        # Record final losses from this run.\n",
    "                        final_train_loss = train_losses[-1]\n",
    "                        final_val_loss = val_losses[-1]\n",
    "                        result = {\n",
    "                            'batch_size': bs,\n",
    "                            'hidden_size': hs,\n",
    "                            'num_epochs': epoch+1,\n",
    "                            'learning_rate': lr,\n",
    "                            'final_train_loss': final_train_loss,\n",
    "                            'final_val_loss': final_val_loss\n",
    "                        }\n",
    "                        tuning_results.append(result)\n",
    "                        \n",
    "                        # Save the model if this run achieved the best validation loss so far.\n",
    "                        if final_val_loss < best_val_loss:\n",
    "                            best_lr = lr\n",
    "                            best_bs = bs\n",
    "                            best_hs = hs\n",
    "                            best_epoch = epoch+1\n",
    "                            best_val_loss = final_val_loss\n",
    "                            best_params = result\n",
    "                            best_model_state = model.state_dict()\n",
    "                            model_name = f\"best_model_hs{hs}_lr{lr}_bs{bs}_epochs{epoch}_val{final_val_loss}.pth\"\n",
    "                            torch.save(best_model_state, f\"best_model_hs{hs}_lr{lr}_bs{bs}_epochs{epoch}_val{final_val_loss}.pth\")\n",
    "                            print(f\"  New best model saved with val loss {best_val_loss:.6f}\")\n",
    "                            # Create a model filename that includes the hyperparameters and validation loss.\n",
    "                            # model_filename = f\"gaitgen_6d_newnorm_hs{hs}_lr{lr}_bs{bs}_epochs{num_epochs}_val{final_val_loss:.4f}.pth\"\n",
    "                            # torch.save(model.state_dict(), os.path.join(results_dir, model_filename))\n",
    "                            # print(f\"  New best model saved as {os.path.join(results_dir, model_filename)}\")\n",
    "\n",
    "                # (Optional) Save a plot of train/val losses for this hyperparameter setting.\n",
    "                plt.figure()\n",
    "                plt.plot(np.arange(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "                plt.plot(np.linspace(10, num_epochs,num =len(val_losses)), val_losses, label='Val Loss')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.legend()\n",
    "                plt.title(f\"bs={bs}, hs={hs}, epochs={num_epochs}, lr={lr}\")\n",
    "                plt.tight_layout()\n",
    "                plot_filename = f\"loss_plot_bs{bs}_hs{hs}_epochs{num_epochs}_lr{lr}.png\"\n",
    "                plt.savefig(os.path.join(results_dir, plot_filename))\n",
    "                plt.close()\n",
    "                print(f\" Loss plot saved as {os.path.join(results_dir, plot_filename)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test dataset and DataLoader\n",
    "test_dataloader = DataLoader(val_data, batch_size=1, shuffle=False)  # Batch size of 5\n",
    "norm_consts = np.load(rf\"gait reference fft5.00/newnormalization_constants.npy\")\n",
    "# Testing loop\n",
    "model = SimpleFCNN(input_size=input_size, output_size=output_size, hidden_size=best_hs)\n",
    "model.load_state_dict(torch.load(model_name))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "k = 0\n",
    "with torch.no_grad():  # No need to compute gradients during testing\n",
    "    for inputs, targets in test_dataloader:\n",
    "        speed = inputs[0,0].item()*3\n",
    "        targets = targets.reshape(-1,204)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "        ground_truth = targets.reshape(-1,6,2,17)\n",
    "        predictions = outputs.reshape(-1,6,2,17)\n",
    "\n",
    "        predictions = predictions.detach().numpy()\n",
    "        predictions = predictions[0]\n",
    "        ground_truth = ground_truth.detach().numpy()\n",
    "        ground_truth = ground_truth[0]\n",
    "\n",
    "        predictions, ground_truth = denormalize(predictions,ground_truth,norm_consts)\n",
    "        pred_time,gt_time = pred_ifft(predictions,ground_truth,speed,norm_consts)\n",
    "        # animate_biped(pred_time,f\"predict_plots_25hs512_fft/{speed:.1f}ms.gif\")\n",
    "        # animate_biped(gt_time,f\"predict_plots_25hs512_fft/{speed:.1f}ms.gif\")\n",
    "        k+=1\n",
    "# Calculate average loss and accuracy\n",
    "test_loss /= len(test_dataloader)  # Average test loss\n",
    "\n",
    "\n",
    "# Print test results\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "plt.plot(targets[0].numpy())\n",
    "plt.plot(outputs[0].numpy())\n",
    "plt.legend(['Ground Truth', 'Predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning is already completed no need to run the following cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(tuning_results)\n",
    "# results_df_filename = os.path.join(results_dir, \"gaitgen_6d_newnorm.csv\")\n",
    "# results_df.to_csv(results_df_filename, index=False)\n",
    "# print(\"Hyperparameter tuning complete.\")\n",
    "# print(\"Best hyperparameters:\")\n",
    "# print(best_params)\n",
    "# print(f\"Best model validation loss: {best_val_loss:.4f}\")\n",
    "# print(f\"Tuning results saved to {results_df_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the Network with the Full Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.load(rf\"gait reference fft5.00/newnormalized_input_vector.npy\")\n",
    "outputs = np.load(rf\"gait reference fft5.00/newnormalized_output_fft_constants.npy\")\n",
    "\n",
    "outputs = outputs.transpose(0,2,3,1)\n",
    "outputs = torch.tensor(outputs, dtype=torch.float32)\n",
    "outputs = outputs.reshape(outputs.shape[0],-1)\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "train_data = TensorDataset(inputs, outputs)\n",
    "\n",
    "# ADJUST THE PARAMETERS BASED ON THE BEST VALIDATION SCORED RESULT\n",
    "bs = best_bs\n",
    "hs = best_hs\n",
    "lr = best_lr\n",
    "train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "\n",
    "num_epochs = best_epoch\n",
    "torch.manual_seed(23)  # Ensure reproducibility per run.\n",
    "model = SimpleFCNN(input_size=input_size, output_size=output_size, hidden_size=hs)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop for the current hyperparameter combination.\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        # Ensure targets are the right shape.\n",
    "        targets = targets.view(-1, output_size)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item() * inputs.size(0)\n",
    "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    if (epoch+1) % 200 == 0 or epoch == num_epochs - 1:\n",
    "        print(f\"  Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_train_loss:.4f}\")\n",
    "\n",
    "model_filename = f\"final_model.pth\"\n",
    "torch.save(model.state_dict(), os.path.join(model_filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biped_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
