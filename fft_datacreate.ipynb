{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ezc3d import c3d\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass_filter(data, cutoff=5, fs=100, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data, axis=0)\n",
    "    return y\n",
    "\n",
    "def extract_gait_cycle(c, gait_duration=3):\n",
    "\n",
    "    times = c[\"parameters\"][\"EVENT\"][\"TIMES\"]['value']\n",
    "    contexts = c[\"parameters\"][\"EVENT\"][\"CONTEXTS\"]['value']\n",
    "    labels = c[\"parameters\"][\"EVENT\"][\"LABELS\"]['value']\n",
    "    gait_points = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        if (labels[i] == \"Foot Strike1\") and (contexts[i] == \"Right\"):\n",
    "            gait_start = int(times[1,i]*100)\n",
    "        if (labels[i] == \"Foot Strike2\") and (contexts[i] == \"Right\"):\n",
    "            gait_end = int(times[1,i]*100)\n",
    "\n",
    "    trial_data = c['data']['points'][:,:,gait_start:gait_end]\n",
    "    labels = c['parameters']['POINT']['LABELS']['value']\n",
    "\n",
    "    #[15,4,16,5,20,9]\n",
    "    r_ftc = labels.index(\"R_FTC\") if \"R_FTC\" in labels else RuntimeError(\"R_FTC not found\")\n",
    "    l_ftc = labels.index(\"L_FTC\") if \"L_FTC\" in labels else RuntimeError(\"L_FTC not found\")\n",
    "    r_fle = labels.index(\"R_FLE\") if \"R_FLE\" in labels else RuntimeError(\"R_FLE not found\")\n",
    "    l_fle = labels.index(\"L_FLE\") if \"L_FLE\" in labels else RuntimeError(\"L_FLE not found\")\n",
    "    r_fal = labels.index(\"R_FCC\") if \"R_FCC\" in labels else RuntimeError(\"R_FCC not found\")\n",
    "    l_fal = labels.index(\"L_FCC\") if \"L_FCC\" in labels else RuntimeError(\"L_FCC not found\")\n",
    "    sxs = labels.index(\"SXS\") if \"SXS\" in labels else RuntimeError(\"SXS not found\")\n",
    "\n",
    "    r_leglength_ind = c['parameters']['SUBJECT']['LABELS']['value'].index(\"R_legLength\") if \"R_legLength\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"R_LEGLENGTH not found\")\n",
    "    l_leglength_ind = c['parameters']['SUBJECT']['LABELS']['value'].index(\"L_legLength\") if \"L_legLength\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"L_LEGLENGTH not found\")\n",
    "    weight = c['parameters']['SUBJECT']['LABELS']['value'].index(\"weight\") if \"weight\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"Weight not found\")\n",
    "    height = c['parameters']['SUBJECT']['LABELS']['value'].index(\"height\") if \"height\" in c['parameters']['SUBJECT']['LABELS']['value'] else RuntimeError(\"Height not found\")\n",
    "    r_leglength = c['parameters']['SUBJECT']['VALUES']['value'][r_leglength_ind]\n",
    "    l_leglength = c['parameters']['SUBJECT']['VALUES']['value'][l_leglength_ind]\n",
    "    weight = c['parameters']['SUBJECT']['VALUES']['value'][weight]\n",
    "    height = c['parameters']['SUBJECT']['VALUES']['value'][height]\n",
    "\n",
    "    muscle_index = [r_ftc,l_ftc,r_fle,l_fle,r_fal,l_fal]\n",
    "    joint_data = trial_data[:,muscle_index,:]\n",
    "    joint_states = np.zeros((joint_data.shape[2],4))\n",
    "\n",
    "    data_len = joint_data.shape[2]\n",
    "\n",
    "\n",
    "    first_pos = trial_data[0,sxs,0]\n",
    "    last_pos = trial_data[0,sxs,-1]\n",
    "\n",
    "    if last_pos > first_pos:\n",
    "        forward_walk = True\n",
    "    else:\n",
    "        forward_walk = False\n",
    "\n",
    "    speed_muscle = trial_data[:,sxs,:]\n",
    "    speed = np.abs(speed_muscle[0,-1]-speed_muscle[0,0])/(len(speed_muscle[0,:]))/10\n",
    "\n",
    "    #data_point[:,-1] = speed\n",
    "\n",
    "    if forward_walk:\n",
    "        for i in range(data_len):\n",
    "            joint_states[i,0] = np.arctan2((joint_data[0,2,i] - joint_data[0,0,i]) , (-joint_data[2,2,i] + joint_data[2,0,i])) \n",
    "            joint_states[i,1] = np.arctan2((joint_data[0,4,i] - joint_data[0,2,i]) , (-joint_data[2,4,i] + joint_data[2,2,i])) - joint_states[i,0]\n",
    "            joint_states[i,2] = np.arctan2((joint_data[0,3,i] - joint_data[0,1,i]) , (-joint_data[2,3,i] + joint_data[2,1,i]))\n",
    "            joint_states[i,3] = np.arctan2((joint_data[0,5,i] - joint_data[0,3,i]) , (-joint_data[2,5,i] + joint_data[2,3,i])) - joint_states[i,2]\n",
    "            # joint_states[i,4] = speed\n",
    "            # joint_states[i,5] = r_leglength\n",
    "            # joint_states[i,6] = l_leglength\n",
    "    else:\n",
    "        for i in range(data_len):\n",
    "            joint_states[i,0] = np.arctan2((-joint_data[0,2,i] + joint_data[0,0,i]) , (-joint_data[2,2,i] + joint_data[2,0,i])) \n",
    "            joint_states[i,1] = np.arctan2((-joint_data[0,4,i] + joint_data[0,2,i]) , (-joint_data[2,4,i] + joint_data[2,2,i])) - joint_states[i,0]\n",
    "            joint_states[i,2] = np.arctan2((-joint_data[0,3,i] + joint_data[0,1,i]) , (-joint_data[2,3,i] + joint_data[2,1,i]))\n",
    "            joint_states[i,3] = np.arctan2((-joint_data[0,5,i] + joint_data[0,3,i]) , (-joint_data[2,5,i] + joint_data[2,3,i])) - joint_states[i,2]\n",
    "            # joint_states[i,4] = speed\n",
    "            # joint_states[i,5] = r_leglength\n",
    "            # joint_states[i,6] = l_leglength\n",
    "    total_gait_sample = 420\n",
    "    joint_states = lowpass_filter(joint_states, cutoff=10, fs=100, order=4)\n",
    "\n",
    "    if joint_states.shape[0] > total_gait_sample:\n",
    "        print(f'gait cycle: {joint_states.shape[1]} longer than {gait_duration} seconds')\n",
    "        \n",
    "    while joint_states.shape[0] < total_gait_sample:\n",
    "        joint_states = np.concatenate((joint_states, joint_states),axis=0)  # Stack horizontally\n",
    "\n",
    "    joint_states = joint_states[:total_gait_sample,:]\n",
    "    padded_joint_states = np.zeros((512, 4))\n",
    "    padded_joint_states[46:46+joint_states.shape[0],:] = joint_states\n",
    "    \n",
    "    joint_states_rfft = np.fft.rfft(padded_joint_states, axis=0, n=512)\n",
    "    real_fft = np.real(joint_states_rfft)\n",
    "    imag_fft = np.imag(joint_states_rfft)\n",
    "    joint_states_rfft = np.stack((real_fft, imag_fft), axis=2)\n",
    "    freq_values = np.fft.rfftfreq(512, 1/100)\n",
    "    encoder_vec = np.empty((3))   # init_pos + speed + r_leglength + l_leglength + ramp_angle = 0\n",
    "    # encoder_vec[0:4] = joint_states[:,0]\n",
    "    encoder_vec[0] = speed/3\n",
    "    encoder_vec[1] = r_leglength\n",
    "    encoder_vec[2] = l_leglength\n",
    "    # encoder_vec[3] = weight / 100  # 100 is the maximum weight in the dataset\n",
    "    # encoder_vec[4] = height / 2    # 1.91 m is the maximum height in the dataset\n",
    "\n",
    "    encoder_vec = encoder_vec[np.newaxis, :]\n",
    "    joint_states_rfft = joint_states_rfft[np.newaxis, :, :] #179 is the maximum value in the dataset\n",
    "    return joint_states_rfft, freq_values, encoder_vec, joint_states[10:-10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_ifft_plots(joint_states_rfft,joint_states,frequencies,path,crop_ind=30):\n",
    "#     frequency = frequencies[crop_ind]\n",
    "#     joint_states_rfft = 180*np.squeeze(joint_states_rfft)\n",
    "#     cropped = joint_states_rfft.copy()\n",
    "#     cropped[crop_ind:,:] = 0\n",
    "#     ifft = np.fft.irfft(cropped, axis=0)\n",
    "#     cropped_ifft = ifft[56:-56,:]\n",
    "#     fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "#     axs[0, 0].plot(joint_states[:,0])\n",
    "#     axs[0, 0].plot(cropped_ifft[:,0])\n",
    "#     axs[0, 0].legend(['Original', 'Reconstructed'])\n",
    "#     axs[0, 0].set_title('Right Shank')\n",
    "#     axs[0, 1].plot(joint_states[:,1])\n",
    "#     axs[0, 1].plot(cropped_ifft[:,1])\n",
    "#     axs[0, 1].set_title('Right Thigh')\n",
    "#     axs[0, 1].legend(['Original', 'Reconstructed'])\n",
    "#     axs[1, 0].plot(joint_states[:,2])\n",
    "#     axs[1, 0].plot(cropped_ifft[:,2])\n",
    "#     axs[1, 0].set_title('Left Shank')\n",
    "#     axs[1, 0].legend(['Original', 'Reconstructed'])\n",
    "#     axs[1, 1].plot(joint_states[:,3])\n",
    "#     axs[1, 1].plot(cropped_ifft[:,3])\n",
    "#     axs[1, 1].set_title('Left Thigh')\n",
    "#     axs[1, 1].legend(['Original', 'Reconstructed'])\n",
    "#     plt.savefig(path+'.png')\n",
    "#     plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gait_duration = 2\n",
    "crop_ind = 25\n",
    "folders = [d for d in os.listdir(os.path.join(os.getcwd(),'dataset')) if os.path.isdir(os.path.join(os.path.join(os.getcwd(),'dataset'), d))]\n",
    "k=0\n",
    "if os.path.exists(f\"gait reference fft_{crop_ind}_plots\") == False:\n",
    "    os.mkdir(f\"gait reference fft_{crop_ind}_plots\")\n",
    "\n",
    "for folder in folders:\n",
    "    folder_len = len(folder)\n",
    "    files = [f for f in os.listdir(os.path.join(os.getcwd(),'dataset',folder)) if f.endswith('.c3d')]\n",
    "    \n",
    "    print(f\"{k}/{len(folders)} is processed current folder is {folder}\") \n",
    "    i = 0\n",
    "    for file in files:\n",
    "        if 'ST' not in file:\n",
    "            c = c3d(os.path.join('dataset',folder,file))\n",
    "            joint_states_rfft, freq_values, encoder_vec, joint_states = extract_gait_cycle(c,gait_duration=gait_duration)\n",
    "            # if np.max(np.abs(joint_states)) > 1:\n",
    "            #     print(f'joint_states max value is greater than 1 in {folder}_{file[:-4]}')\n",
    "            #     break\n",
    "            if i == 0:\n",
    "                folder_output_state = joint_states_rfft\n",
    "                folder_input_vector = encoder_vec\n",
    "            else:\n",
    "                folder_output_state = np.vstack((folder_output_state,joint_states_rfft))\n",
    "                folder_input_vector = np.vstack((folder_input_vector,encoder_vec))\n",
    "            i+=1\n",
    "    print('folder_output_state_shape: ',folder_output_state.shape)\n",
    "    print('folder input vector shape: ',folder_input_vector.shape)\n",
    "    print('-----------------------------------')\n",
    "    if k == 0:\n",
    "        total_output_state = folder_output_state\n",
    "        total_input_vector = folder_input_vector\n",
    "    else:\n",
    "        total_output_state = np.vstack((total_output_state,folder_output_state))\n",
    "        total_input_vector = np.vstack((total_input_vector,folder_input_vector))\n",
    "    k+=1\n",
    "#     np.save(f\"ref_gait_library_duration{gait_duration}/{folder}_output_state.npy\",folder_output_state)\n",
    "#     np.save(f\"ref_gait_library_duration{gait_duration}/{folder}_input_vector.npy\",folder_input_vector)\n",
    "\n",
    "if os.path.exists(f\"gait reference fft_{crop_ind}_{freq_values[crop_ind]:.2f}\") == False:\n",
    "    os.mkdir(f\"gait reference fft_{crop_ind}_{freq_values[crop_ind]:.2f}\")\n",
    "\n",
    "np.save(f\"gait reference fft_{crop_ind}_{freq_values[crop_ind]:.2f}/output_fft_constants.npy\",total_output_state)\n",
    "np.save(f\"gait reference fft_{crop_ind}_{freq_values[crop_ind]:.2f}/input_vector.npy\",total_input_vector)\n",
    "\n",
    "print('total output state ',total_output_state.shape)\n",
    "print('total input vector ',total_input_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZATION OF THE DATA IS IMPLEMENTED\n",
    "import numpy as np\n",
    "real_rthigh = np.max(np.abs(total_output_state[:,:,0,0]))\n",
    "imag_rthigh = np.max(np.abs(total_output_state[:,:,0,1]))\n",
    "real_rshank = np.max(np.abs(total_output_state[:,:,1,0]))\n",
    "imag_rshank = np.max(np.abs(total_output_state[:,:,1,1]))\n",
    "real_lthigh = np.max(np.abs(total_output_state[:,:,2,0]))\n",
    "imag_lthigh = np.max(np.abs(total_output_state[:,:,2,1]))\n",
    "real_lshank = np.max(np.abs(total_output_state[:,:,3,0]))\n",
    "imag_lshank = np.max(np.abs(total_output_state[:,:,3,1]))\n",
    "\n",
    "print(real_rthigh,imag_rthigh,real_rshank,imag_rshank,real_lthigh,imag_lthigh,real_lshank,imag_lshank) \n",
    "\n",
    "normalizationconst = np.array([real_rthigh,imag_rthigh,real_rshank,imag_rshank,real_lthigh,imag_lthigh,real_lshank,imag_lshank])\n",
    "\n",
    "total_output_state[:,:,0,0] = total_output_state[:,:,0,0] / real_rthigh\n",
    "total_output_state[:,:,1,0] = total_output_state[:,:,1,0] / real_rshank\n",
    "total_output_state[:,:,2,0] = total_output_state[:,:,2,0] / real_lthigh\n",
    "total_output_state[:,:,3,0] = total_output_state[:,:,3,0] / real_lshank\n",
    "\n",
    "total_output_state[:,:,0,1] = total_output_state[:,:,0,1] / imag_rthigh\n",
    "total_output_state[:,:,1,1] = total_output_state[:,:,1,1] / imag_rshank\n",
    "total_output_state[:,:,2,1] = total_output_state[:,:,2,1] / imag_lthigh\n",
    "total_output_state[:,:,3,1] = total_output_state[:,:,3,1] / imag_lshank\n",
    "\n",
    "np.save(f\"gait reference fft_{crop_ind}_{freq_values[crop_ind]:.2f}/normalized_output_fft_constants.npy\",total_output_state)\n",
    "np.save(f\"gait reference fft_{crop_ind}_{freq_values[crop_ind]:.2f}/normalized_input_vector.npy\",total_input_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"gait reference fft_{crop_ind}_{freq_values[crop_ind]:.2f}/normalization_constants.npy\",normalizationconst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "inputs = np.load(rf\"gait reference fft_25_4.88\\normalized_input_vector.npy\")\n",
    "outputs = np.load(rf\"gait reference fft_25_4.88\\normalized_output_fft_constants.npy\")\n",
    "\n",
    "#train test split using sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.01, random_state=23)\n",
    "\n",
    "y_train = y_train[:,:25,:]\n",
    "y_train  = y_train.transpose(0,3,1,2)\n",
    "y_test = y_test[:,:25,:]\n",
    "y_test = y_test.transpose(0,3,1,2)\n",
    "#convert to tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# create dataloader\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "print('train data shape: ',X_train.shape)\n",
    "print('test data shape: ',X_test.shape)\n",
    "print('train output shape: ',y_train.shape)\n",
    "print('test output shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(pred,gt,normalizationconst):\n",
    "\n",
    "    pred[0,:,0] = pred[0,:,0] * normalizationconst[0]\n",
    "    pred[0,:,1] = pred[0,:,1] * normalizationconst[1]\n",
    "    pred[0,:,2] = pred[0,:,2] * normalizationconst[2]\n",
    "    pred[0,:,3] = pred[0,:,3] * normalizationconst[3]\n",
    "    pred[1,:,0] = pred[1,:,0] * normalizationconst[4]\n",
    "    pred[1,:,1] = pred[1,:,1] * normalizationconst[5]\n",
    "    pred[1,:,2] = pred[1,:,2] * normalizationconst[6]\n",
    "    pred[1,:,3] = pred[1,:,3] * normalizationconst[7]\n",
    "\n",
    "    gt[0,:,0] = gt[0,:,0] * normalizationconst[0]\n",
    "    gt[0,:,1] = gt[0,:,1] * normalizationconst[1]\n",
    "    gt[0,:,2] = gt[0,:,2] * normalizationconst[2]\n",
    "    gt[0,:,3] = gt[0,:,3] * normalizationconst[3]\n",
    "    gt[1,:,0] = gt[1,:,0] * normalizationconst[4]\n",
    "    gt[1,:,1] = gt[1,:,1] * normalizationconst[5]\n",
    "    gt[1,:,2] = gt[1,:,2] * normalizationconst[6]\n",
    "    gt[1,:,3] = gt[1,:,3] * normalizationconst[7]\n",
    "    \n",
    "    return pred,gt\n",
    "    \n",
    "\n",
    "def pred_ifft(predictions,ground_truth,speed,normalizationconst):\n",
    "\n",
    "    real_pred = predictions[0,:,:]\n",
    "    imag_pred = predictions[0,:,:]\n",
    "    predictions = real_pred + 1j*imag_pred\n",
    "    real_gt = ground_truth[0,:,:]\n",
    "    imag_gt = ground_truth[1,:,:]\n",
    "    ground_truth = real_gt + 1j*imag_gt\n",
    "    \n",
    "    padded_pred = np.zeros((257,4),dtype=complex)\n",
    "    padded_pred[:25,:] = predictions\n",
    "    padded_gt = np.zeros((257,4),dtype=complex)\n",
    "    padded_gt[:25,:] = ground_truth\n",
    "\n",
    "    padded_time = np.fft.irfft(padded_pred, axis=0)\n",
    "    pred_time = padded_time[56:-56,:]\n",
    "    gt_time = np.fft.irfft(padded_gt, axis=0)\n",
    "    gt_time = gt_time[56:-56,:]\n",
    "    #plot 2*2 subplots\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(pred_time[:,0])\n",
    "    plt.plot(gt_time[:,0])\n",
    "    plt.title('Right Shank')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(pred_time[:,1])\n",
    "    plt.plot(gt_time[:,1])\n",
    "    plt.title('Right Thigh')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(pred_time[:,2])\n",
    "    plt.plot(gt_time[:,2])\n",
    "    plt.title('Left Shank')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(pred_time[:,3])\n",
    "    plt.plot(gt_time[:,3])\n",
    "    plt.title('Left Thigh')\n",
    "    plt.legend(['Predicted','Ground Truth'])\n",
    "    plt.savefig(f\"predict_plots_25hs512_fft/{speed:.1f}ms.png\")\n",
    "    plt.close()\n",
    "    print('plots saved')\n",
    "    return pred_time,gt_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super(WeightedMSELoss, self).__init__()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Element-wise weighted MSE\n",
    "        loss = self.weights * (predictions - targets) ** 2\n",
    "        return loss.mean()\n",
    "\n",
    "# Example weights: first 10 have weight 10, the rest have weight 1\n",
    "\n",
    "class large_penalized_mse(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(large_penalized_mse, self).__init__()\n",
    "    \"\"\"\n",
    "    Custom MSE loss function that penalizes the first 100 outputs more\n",
    "    if their absolute values exceed the target values.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Tensor of shape (batch_size, 200)\n",
    "        targets: Tensor of shape (batch_size, 200)\n",
    "        weight_factor: Penalty factor for the first 100 outputs when they exceed the target.\n",
    "    \"\"\"\n",
    "    def forward(self, predictions, targets):\n",
    "        weight_factor=2.0\n",
    "        # Compute standard MSE for all outputs\n",
    "        mse_loss = (predictions - targets) ** 2\n",
    "        \n",
    "        # Separate the first 100 and last 100 outputs\n",
    "        first_100_preds = predictions[:, :100]\n",
    "        first_100_targets = targets[:, :100]\n",
    "        \n",
    "        # Condition for penalizing: predictions > targets (element-wise)\n",
    "        penalty_mask = (first_100_preds > first_100_targets).float()\n",
    "        \n",
    "        # Apply the weight factor to the first 100 outputs where the condition is met\n",
    "        weighted_first_100_loss = mse_loss[:, :100] * (1 + penalty_mask * (weight_factor - 1))\n",
    "        \n",
    "        # Combine the weighted first 100 loss and the regular last 100 loss\n",
    "        combined_loss = torch.cat([weighted_first_100_loss, mse_loss[:, 100:]], dim=1)\n",
    "        \n",
    "        # Return the mean loss\n",
    "        return combined_loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleFCNN(nn.Module):\n",
    "    def __init__(self, input_size=3, output_size=160, hidden_size=128):\n",
    "        super(SimpleFCNN, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input to hidden layer\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) # Hidden to output layer\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()                          # Activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply layers with activation function\n",
    "        x = self.fc1(x)         # Hidden layer\n",
    "        x = nn.Dropout(0.5)(x)\n",
    "        x = self.relu(x)        # Activation function\n",
    "        x = self.fc2(x)         # Hidden layer\n",
    "        x = nn.Dropout(0.5)(x)\n",
    "        x = self.relu(x)        # Activation function\n",
    "        x = self.fc3(x)         # Output layer\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "torch.manual_seed(23)\n",
    "input_size = 3\n",
    "output_size = 200\n",
    "hidden_size = 512\n",
    "model = SimpleFCNN(input_size=input_size, output_size=output_size,hidden_size=hidden_size)\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Generate synthetic data for demonstration\n",
    "weights = torch.tensor([1.0] * 200)\n",
    "# weights[:40] = 3\n",
    "# weights[100:40] = 3\n",
    "# loss_fn = WeightedMSELoss(weights)\n",
    "# loss_fn = nn.MSELoss()\n",
    "loss_fn = large_penalized_mse()\n",
    "# Create a dataset and DataLoader\n",
    "dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "losses = []\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, targets in dataloader:\n",
    "        targets = targets.reshape(-1,200)\n",
    "\n",
    "        # Zero the gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    losses.append(running_loss)\n",
    "    \n",
    "    # Print epoch loss\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n",
    "plt.plot(losses)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"model_hs{hidden_size}_lpmse_bs{batch_size}_epoch{num_epochs}_fft.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def animate_biped(angles,filename):\n",
    "    \"\"\"\n",
    "    Animate a 2D bipedal robot given an n*4 array of angles.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    angles : np.ndarray\n",
    "        A numpy array of shape (n,4), where n is the number of time steps.\n",
    "        Each row: [right_shank_angle, right_thigh_angle, left_shank_angle, left_thigh_angle]\n",
    "    \"\"\"\n",
    "    num_frames = angles.shape[0]\n",
    "    seg_length = 1.0\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2.5, 2.5)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Lines\n",
    "    torso_line, = ax.plot([], [], 'k-', lw=2)\n",
    "    right_thigh_line, = ax.plot([], [], 'b-', lw=2)\n",
    "    right_shank_line, = ax.plot([], [], 'r-', lw=2)\n",
    "    left_thigh_line, = ax.plot([], [], 'g-', lw=2)\n",
    "    left_shank_line, = ax.plot([], [], 'm-', lw=2)\n",
    "\n",
    "    # Scatter points for joints\n",
    "    hip_marker = ax.scatter([], [], c='black', s=50)\n",
    "    right_knee_marker = ax.scatter([], [], c='blue', s=50)\n",
    "    right_foot_marker = ax.scatter([], [], c='red', s=50)\n",
    "    left_knee_marker = ax.scatter([], [], c='green', s=50)\n",
    "    left_foot_marker = ax.scatter([], [], c='magenta', s=50)\n",
    "\n",
    "    # Initialization function for FuncAnimation\n",
    "    def init():\n",
    "        torso_line.set_data([], [])\n",
    "        right_thigh_line.set_data([], [])\n",
    "        right_shank_line.set_data([], [])\n",
    "        left_thigh_line.set_data([], [])\n",
    "        left_shank_line.set_data([], [])\n",
    "\n",
    "        # Set empty offsets as a (0,2) shaped array\n",
    "        hip_marker.set_offsets(np.empty((0, 2)))\n",
    "        right_knee_marker.set_offsets(np.empty((0, 2)))\n",
    "        right_foot_marker.set_offsets(np.empty((0, 2)))\n",
    "        left_knee_marker.set_offsets(np.empty((0, 2)))\n",
    "        left_foot_marker.set_offsets(np.empty((0, 2)))\n",
    "\n",
    "        return (torso_line, right_thigh_line, right_shank_line, \n",
    "                left_thigh_line, left_shank_line, hip_marker, \n",
    "                right_knee_marker, right_foot_marker, \n",
    "                left_knee_marker, left_foot_marker)\n",
    "\n",
    "    def update(frame):\n",
    "        ax.set_title(f\"Time Step: {frame + 1}\")\n",
    "        r_thigh_angle, r_shank_angle, l_thigh_angle, l_shank_angle = angles[frame]\n",
    "\n",
    "        # Hip at origin\n",
    "        hip_pos = np.array([0.0, 0.0])\n",
    "        # Simple torso line upwards\n",
    "        torso_top = np.array([0.0, 1.0])\n",
    "        torso_line.set_data([torso_top[0], hip_pos[0]], [torso_top[1], hip_pos[1]])\n",
    "\n",
    "        # Right leg\n",
    "        right_knee = hip_pos + seg_length * np.array([np.sin(r_thigh_angle), -np.cos(r_thigh_angle)])\n",
    "        right_foot = right_knee + seg_length * np.array([np.sin(r_thigh_angle + r_shank_angle), -np.cos(r_thigh_angle + r_shank_angle)])\n",
    "        right_thigh_line.set_data([hip_pos[0], right_knee[0]], [hip_pos[1], right_knee[1]])\n",
    "        right_shank_line.set_data([right_knee[0], right_foot[0]], [right_knee[1], right_foot[1]])\n",
    "\n",
    "        # Left leg\n",
    "        left_knee = hip_pos + seg_length * np.array([np.sin(l_thigh_angle), -np.cos(l_thigh_angle)])\n",
    "        left_foot = left_knee + seg_length * np.array([np.sin(l_thigh_angle + l_shank_angle), -np.cos(l_thigh_angle + l_shank_angle)])\n",
    "        left_thigh_line.set_data([hip_pos[0], left_knee[0]], [hip_pos[1], left_knee[1]])\n",
    "        left_shank_line.set_data([left_knee[0], left_foot[0]], [left_knee[1], left_foot[1]])\n",
    "\n",
    "        # Update markers with a 2D array shape\n",
    "        hip_marker.set_offsets([hip_pos])\n",
    "        right_knee_marker.set_offsets([right_knee])\n",
    "        right_foot_marker.set_offsets([right_foot])\n",
    "        left_knee_marker.set_offsets([left_knee])\n",
    "        left_foot_marker.set_offsets([left_foot])\n",
    "\n",
    "        return (torso_line, right_thigh_line, right_shank_line, \n",
    "                left_thigh_line, left_shank_line, hip_marker, \n",
    "                right_knee_marker, right_foot_marker, \n",
    "                left_knee_marker, left_foot_marker)\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=num_frames, init_func=init, interval=1, blit=False)\n",
    "    ani.save(filename, fps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test dataset and DataLoader\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)  # Batch size of 5\n",
    "norm_consts = np.load(rf\"gait reference fft_25_4.88\\normalization_constants.npy\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "k = 0\n",
    "with torch.no_grad():  # No need to compute gradients during testing\n",
    "    for inputs, targets in test_dataloader:\n",
    "        speed = inputs[0,0].item()*3\n",
    "\n",
    "\n",
    "        targets = targets.reshape(-1,200)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "        ground_truth = targets.reshape(-1,2,25,4)\n",
    "        predictions = outputs.reshape(-1,2,25,4)\n",
    "\n",
    "        predictions = predictions.detach().numpy()\n",
    "        predictions = predictions[0]\n",
    "        ground_truth = ground_truth.detach().numpy()\n",
    "        ground_truth = ground_truth[0]\n",
    "\n",
    "        predictions, ground_truth = denormalize(predictions,ground_truth,norm_consts)\n",
    "        pred_time,gt_time = pred_ifft(predictions,ground_truth,speed,norm_consts)\n",
    "        animate_biped(pred_time,f\"predict_plots_25hs512_fft/{speed:.1f}ms.gif\")\n",
    "        animate_biped(gt_time,f\"predict_plots_25hs512_fft/{speed:.1f}ms.gif\")\n",
    "        k+=1\n",
    "# Calculate average loss and accuracy\n",
    "test_loss /= len(test_dataloader)  # Average test loss\n",
    "\n",
    "\n",
    "# Print test results\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "plt.plot(targets[0].numpy())\n",
    "plt.plot(outputs[0].numpy())\n",
    "plt.legend(['Ground Truth', 'Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def ifft(predictions):\n",
    "    padded_pred = np.zeros((257,4),dtype=complex)\n",
    "    pred_real = predictions[:,:,0]\n",
    "    pred_imag = predictions[:,:,1]\n",
    "    predictions = pred_real + 1j*pred_imag\n",
    "    padded_pred[:20,:] = predictions*180\n",
    "    padded_time = np.fft.irfft(padded_pred, axis=0)\n",
    "    pred_time = padded_time[56:-56,:]*90\n",
    "    return pred_time\n",
    "\n",
    "\n",
    "def test_ifft(predictions):\n",
    "    pred_real = predictions[:,:,0]\n",
    "    pred_imag = predictions[:,:,1]\n",
    "    predictions = pred_real + 1j*pred_imag\n",
    "    time_signal = np.fft.irfft(predictions, axis=0)\n",
    "    pred_time = time_signal[56:-56,:]*90\n",
    "    return pred_time\n",
    "\n",
    "# model.eval()\n",
    "# output = model(X_test[0].reshape(1,5))\n",
    "# target = y_test[0]\n",
    "# print(target.shape)\n",
    "# predictions = outputs.reshape(-1,20,4)\n",
    "# predictions = predictions.detach().numpy()\n",
    "\n",
    "# animate_biped(ifft_pred*(np.pi/2))\n",
    "a = np.load(r\"gait reference fft_20_3.91\\normalized_output_fft_constants.npy\")\n",
    "a = a[12,:,:,:]\n",
    "b = test_ifft(a)\n",
    "animate_biped(b)\n",
    "print(a.shape)\n",
    "# animate_biped(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
